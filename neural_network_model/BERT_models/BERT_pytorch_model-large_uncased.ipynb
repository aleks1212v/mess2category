{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNKaJz5j_ylj"
   },
   "source": [
    "# Классификация обращений граждан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "## Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "0NmMdkZO8R6q",
    "outputId": "1cc59bfa-1dbb-4540-cb22-196f399f62af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.95)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.22.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.53)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.53 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.20.53)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.12.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.5.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2019.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ok002ceNB8E7",
    "outputId": "06ef90d2-7518-4209-da66-1dd45c357c78"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import random\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oYsV4H8fCpZ-",
    "outputId": "b8812c8e-3149-475f-b4c0-262160485c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cpu':\n",
    "    print('cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "## Загрузка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "data = pd.read_csv('tatarstan_message_2.csv', encoding='utf8', sep=',')\n",
    "data = data[['categories', 'description_prep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>description_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>Содержание и ремонт муниципальных дорог</td>\n",
       "      <td>за всю зиму ни разу не приезжал трактор терпел...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>Благоустройство территории</td>\n",
       "      <td>добрый день медиа фасад на доме по ул вишневск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>Нарушение в наружной рекламе</td>\n",
       "      <td>перед поворотом отвлекал один баннер прием лом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>Содержание и ремонт муниципальных дорог</td>\n",
       "      <td>необходимо почистить от снега спуск с перекрес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>Благоустройство территории</td>\n",
       "      <td>просьба привести в порядок территорию централь...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    categories  \\\n",
       "20046  Содержание и ремонт муниципальных дорог   \n",
       "8630                Благоустройство территории   \n",
       "13305             Нарушение в наружной рекламе   \n",
       "1912   Содержание и ремонт муниципальных дорог   \n",
       "22950               Благоустройство территории   \n",
       "\n",
       "                                        description_prep  \n",
       "20046  за всю зиму ни разу не приезжал трактор терпел...  \n",
       "8630   добрый день медиа фасад на доме по ул вишневск...  \n",
       "13305  перед поворотом отвлекал один баннер прием лом...  \n",
       "1912   необходимо почистить от снега спуск с перекрес...  \n",
       "22950  просьба привести в порядок территорию централь...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"[CLS] \" + str(x) + \" [SEP]\" for x in data['description_prep']]\n",
    "#len_s = len(sentences)//2\n",
    "#labels = pd.Series([[0]] * len_s + [[1]] * (len(sentences) - len_s -10 ) + [[2]] * 10).values.tolist()\n",
    "#labels = pd.get_dummies(labels).values.tolist()\n",
    "labels = pd.get_dummies(data['categories'])\n",
    "label_names = labels.columns.tolist()\n",
    "labels.columns = range(len(labels.columns))\n",
    "labels = labels * labels.columns\n",
    "labels['sum'] = labels.sum(axis=1)\n",
    "num_labels = max(labels['sum']) + 1\n",
    "labels = [[lab] for lab in labels['sum']]\n",
    "\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [2], [23], [2], [23], [16], [2], [2], [23], [23], [23], [2], [2], [2], [1], [15], [23], [2], [23], [2], [1], [1], [2], [23], [2], [23], [23], [23], [9], [14], [15], [15], [1], [23], [2], [2], [15], [23], [2], [2], [2], [2], [2], [23], [16], [11], [16], [2], [23], [23], [2], [14], [2], [16], [23], [23], [21], [1], [2], [23], [23], [2], [16], [1], [23], [23], [2], [2], [23], [2], [2], [2], [23], [10], [10], [10], [10], [10], [10], [10], [10], [10], [16], [16], [14], [1], [18], [14], [2], [23], [23], [2], [23], [2], [2], [2], [23], [2], [2], [23], [23], [23], [2], [2], [2], [23], [23], [1], [23], [23], [23], [23], [15], [23], [23], [2], [23], [23], [2], [23], [23], [8], [2], [23], [23], [23], [15], [2], [2], [2], [23], [2], [23], [23], [23], [8], [2], [2], [2], [2], [2], [23], [2], [2], [23], [23], [1], [2], [23], [2], [23], [2], [2], [23], [23], [1], [2], [2], [2], [2], [23], [14], [23], [15], [2], [23], [23], [23], [2], [23], [2], [14], [21], [23], [14], [23], [12], [2], [2], [23], [23], [14], [23], [23], [2], [23], [12], [23], [2], [23], [2], [4], [14], [23], [23], [23], [23], [23], [2], [23], [23], [2], [23], [23], [23], [23], [23], [2], [23], [14], [2], [10], [2], [23], [2], [2], [23], [10], [2], [2], [23], [2], [15], [15], [2], [2], [2], [10], [23], [1], [23], [2], [2], [23], [1], [23], [2], [23], [2], [23], [23], [2], [23], [23], [23], [23], [20], [10], [23], [23], [2], [2], [23], [2], [23], [15], [2], [23], [2], [23], [23], [2], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [23], [23], [23], [2], [23], [12], [23], [16], [23], [18], [2], [2], [12], [23], [23], [23], [23], [1], [2], [2], [2], [2], [23], [23], [2], [2], [15], [2], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [21], [2], [23], [23], [23], [2], [2], [23], [23], [2], [23], [23], [2], [2], [23], [23], [16], [23], [23], [23], [5], [23], [5], [2], [14], [1], [23], [2], [12], [23], [23], [16], [12], [2], [2], [2], [23], [23], [12], [2], [2], [23], [2], [2], [23], [2], [18], [15], [2], [23], [2], [2], [23], [12], [2], [1], [23], [12], [2], [23], [2], [12], [16], [23], [2], [23], [12], [12], [23], [23], [23], [2], [12], [23], [23], [2], [23], [23], [23], [2], [2], [23], [23], [2], [23], [2], [2], [23], [23], [16], [23], [23], [12], [23], [2], [23], [12], [23], [2], [23], [23], [2], [23], [23], [2], [23], [23], [2], [23], [12], [6], [1], [2], [2], [23], [2], [23], [23], [23], [23], [7], [23], [23], [1], [23], [23], [2], [23], [23], [2], [23], [2], [23], [23], [23], [23], [2], [23], [14], [2], [23], [23], [1], [5], [14], [12], [2], [12], [23], [4], [23], [23], [23], [2], [16], [23], [1], [23], [23], [23], [23], [1], [16], [1], [23], [2], [12], [23], [12], [23], [16], [14], [23], [23], [14], [2], [23], [2], [2], [23], [23], [23], [2], [15], [23], [23], [17], [2], [23], [9], [23], [23], [23], [23], [23], [2], [23], [23], [2], [23], [2], [2], [23], [23], [15], [1], [14], [2], [23], [16], [23], [23], [2], [23], [16], [2], [2], [2], [23], [2], [23], [23], [2], [2], [2], [23], [2], [1], [23], [23], [23], [23], [14], [2], [14], [10], [10], [12], [10], [2], [23], [23], [2], [2], [2], [16], [23], [14], [2], [23], [14], [16], [23], [2], [2], [1], [23], [2], [2], [23], [23], [23], [2], [23], [2], [23], [12], [2], [23], [23], [5], [2], [2], [2], [2], [23], [23], [23], [2], [15], [2], [6], [2], [23], [1], [16], [23], [2], [14], [23], [14], [8], [23], [14], [2], [10], [1], [2], [23], [12], [15], [17], [2], [14], [2], [2], [2], [2], [23], [14], [2], [23], [23], [23], [2], [12], [23], [18], [23], [1], [14], [23], [2], [2], [2], [2], [2], [23], [14], [2], [23], [1], [14], [23], [23], [2], [14], [23], [23], [14], [23], [23], [23], [1], [23], [2], [23], [2], [16], [2], [4], [23], [2], [2], [2], [2], [1], [23], [2], [2], [23], [23], [23], [2], [2], [2], [5], [23], [23], [2], [2], [2], [2], [2], [16], [2], [23], [2], [2], [2], [2], [2], [23], [2], [14], [2], [23], [23], [2], [2], [2], [2], [14], [2], [2], [23], [23], [2], [2], [15], [23], [2], [14], [10], [23], [23], [23], [23], [23], [23], [14], [1], [23], [14], [20], [23], [2], [23], [23], [2], [23], [14], [1], [2], [23], [23], [14], [10], [2], [15], [14], [2], [23], [2], [12], [1], [1], [2], [2], [16], [14], [2], [23], [2], [2], [8], [23], [14], [2], [14], [23], [23], [23], [14], [12], [5], [14], [1], [1], [23], [2], [23], [15], [10], [2], [23], [2], [23], [2], [2], [2], [10], [23], [23], [23], [2], [23], [23], [23], [23], [2], [23], [23], [23], [2], [2], [23], [12], [14], [1], [2], [23], [23], [23], [23], [23], [2], [23], [12], [23], [10], [23], [2], [10], [23], [16], [14], [15], [8], [2], [14], [16], [23], [2], [10], [23], [23], [14], [2], [23], [23], [23], [23], [2], [1], [14], [10], [2], [2], [2], [23], [2], [2], [23], [2], [10], [23], [23], [2], [2], [14], [2], [1], [2], [2], [2], [23], [2], [16], [2], [2], [23], [2], [23], [1], [2], [16], [2], [2], [23], [23], [2], [1], [2], [23], [12], [14], [2], [23], [23], [23], [2], [2], [12], [12], [14], [2], [2], [14], [23], [2], [14], [23], [1], [23], [23], [9], [14], [14], [23], [2], [2], [23], [23], [23], [23], [23], [2], [23], [12], [23], [1], [1], [23], [14], [23], [23], [23], [2], [2], [14], [12], [2], [2], [14], [23], [2], [23], [14], [1], [1], [1], [2], [2], [2], [23], [23], [23], [23], [2], [2], [23], [23], [16], [23], [23], [23], [14], [2], [23], [14], [23], [23], [2], [23], [2], [14], [23], [23], [2], [10], [5], [23], [23], [2], [23], [23], [23], [23], [23], [23], [5], [23], [23], [23], [2], [23], [23], [23], [1], [9], [23], [14], [23], [23], [2], [1], [23], [23], [2], [23], [1], [23], [23], [23], [23], [2], [23], [23], [23], [2], [1], [2], [2], [7], [23], [2], [2], [2], [23], [23], [2], [2], [23], [23], [2], [23], [23], [23], [2], [23], [8], [2], [2], [1], [23], [2], [2], [2], [10], [16], [1], [1], [23], [16], [23], [2], [2], [23], [23], [12], [10], [15], [2], [2], [5], [2], [2], [23], [2], [2], [23], [23], [23], [23], [14], [16], [23], [23], [23], [12], [23], [3], [2], [23], [14], [14], [23], [23], [23], [21], [23], [14], [23], [12], [23], [2], [2], [2], [2], [23], [14], [23], [23], [23], [2], [2], [2], [23], [1], [1], [2], [2], [23], [23], [23], [23], [2], [2], [2], [23], [2], [23], [2], [2], [23], [23], [23], [23], [23], [2], [23], [23], [2], [23], [2], [23], [2], [23], [23], [23], [23], [1], [23], [23], [23], [16], [2], [2], [23], [2], [23], [1], [16], [2], [2], [8], [23], [2], [23], [2], [23], [23], [2], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [2], [2], [23], [2], [2], [23], [23], [23], [2], [6], [2], [23], [2], [23], [2], [2], [2], [23], [2], [23], [23], [23], [23], [23], [23], [2], [23], [23], [23], [23], [1], [23], [23], [23], [23], [23], [23], [2], [23], [23], [14], [23], [16], [14], [23], [23], [2], [23], [23], [2], [2], [23], [23], [10], [23], [23], [2], [2], [23], [12], [23], [15], [2], [14], [23], [23], [23], [2], [23], [2], [23], [2], [23], [10], [23], [24], [2], [12], [12], [2], [2], [23], [12], [6], [23], [14], [9], [2], [16], [2], [12], [23], [2], [23], [2], [14], [23], [2], [16], [24], [2], [12], [23], [23], [2], [2], [16], [23], [2], [2], [14], [2], [10], [14], [2], [10], [12], [10], [0], [10], [2], [16], [2], [10], [5], [23], [5], [2], [23], [23], [16], [23], [1], [14], [2], [2], [23], [2], [2], [2], [2], [23], [23], [2], [2], [1], [14], [2], [2], [23], [2], [23], [1], [2], [23], [14], [2], [23], [0], [23], [10], [12], [23], [1], [10], [4], [23], [23], [10], [23], [2], [23], [2], [23], [23], [23], [23], [2], [12], [14], [23], [10], [2], [14], [23], [2], [2], [23], [23], [2], [2], [14], [2], [23], [23], [2], [2], [2], [14], [8], [16], [23], [2], [14], [23], [23], [4], [2], [2], [23], [1], [16], [2], [23], [23], [23], [2], [2], [14], [1], [16], [23], [23], [23], [23], [12], [2], [15], [16], [12], [16], [23], [23], [23], [2], [2], [2], [23], [23], [2], [2], [14], [23], [2], [23], [1], [23], [10], [14], [23], [2], [23], [19], [23], [23], [2], [2], [9], [4], [12], [10], [23], [10], [23], [5], [23], [23], [14], [23], [1], [2], [2], [23], [16], [14], [23], [1], [2], [2], [23], [23], [16], [14], [2], [14], [1], [2], [23], [23], [1], [23], [23], [23], [16], [14], [2], [14], [23], [10], [2], [23], [1], [1], [2], [1], [2], [1], [2], [23], [2], [2], [1], [1], [23], [2], [23], [18], [23], [23], [1], [2], [12], [0], [2], [1], [23], [23], [11], [23], [23], [2], [16], [23], [10], [1], [2], [12], [12], [2], [1], [2], [23], [2], [23], [23], [2], [23], [2], [14], [15], [12], [14], [16], [23], [23], [23], [2], [2], [23], [16], [23], [14], [2], [2], [14], [2], [2], [2], [15], [23], [14], [1], [1], [2], [12], [2], [2], [23], [14], [2], [2], [12], [2], [23], [9], [1], [14], [23], [12], [2], [23], [23], [2], [14], [14], [23], [23], [14], [14], [2], [14], [1], [1], [2], [14], [14], [1], [2], [23], [2], [23], [23], [23], [23], [23], [23], [2], [12], [24], [14], [14], [2], [1], [2], [12], [2], [16], [2], [23], [10], [10], [10], [10], [10], [10], [23], [10], [10], [10], [10], [23], [10], [10], [1], [10], [10], [10], [10], [10], [2], [10], [6], [17], [1], [23], [23], [1], [23], [23], [23], [2], [16], [4], [5], [12], [12], [12], [2], [2], [12], [2], [2], [23], [23], [1], [23], [2], [23], [2], [2], [23], [2], [23], [23], [2], [2], [1], [1], [23], [10], [16], [23], [2], [23], [14], [2], [23], [23], [2], [15], [1], [16], [23], [23], [23], [23], [14], [2], [17], [2], [2], [12], [2], [23], [23], [12], [2], [1], [12], [16], [14], [2], [23], [23], [1], [2], [2], [2], [23], [23], [2], [7], [1], [15], [2], [2], [23], [23], [2], [9], [2], [1], [2], [1], [1], [1], [14], [12], [23], [2], [2], [2], [2], [14], [2], [2], [14], [15], [2], [23], [1], [23], [2], [1], [2], [2], [2], [2], [1], [2], [23], [2], [23], [2], [10], [23], [2], [23], [10], [10], [12], [2], [2], [23], [2], [1], [23], [23], [12], [23], [12], [14], [1], [23], [2], [23], [23], [23], [23], [16], [2], [23], [23], [12], [2], [23], [2], [14], [23], [10], [23], [2], [1], [2], [2], [2], [23], [23], [14], [23], [12], [2], [1], [16], [23], [23], [23], [2], [14], [2], [23], [23], [12], [23], [3], [12], [23], [23], [23], [2], [2], [2], [12], [2], [23], [23], [23], [23], [23], [23], [23], [23], [1], [23], [2], [23], [1], [23], [14], [2], [14], [12], [23], [2], [10], [1], [2], [10], [23], [23], [14], [2], [10], [1], [2], [12], [2], [5], [2], [23], [23], [2], [23], [23], [2], [2], [2], [15], [2], [23], [23], [12], [23], [14], [2], [12], [2], [10], [2], [1], [2], [23], [9], [23], [12], [2], [16], [12], [1], [23], [23], [14], [16], [14], [2], [1], [3], [23], [2], [2], [2], [23], [23], [2], [2], [23], [10], [2], [23], [23], [16], [2], [16], [1], [23], [14], [2], [23], [14], [14], [14], [2], [23], [16], [10], [23], [14], [2], [23], [23], [23], [23], [23], [23], [16], [23], [23], [23], [23], [10], [16], [1], [23], [23], [1], [23], [23], [23], [23], [23], [23], [23], [5], [1], [23], [23], [23], [14], [23], [23], [2], [14], [2], [23], [23], [23], [2], [23], [12], [23], [14], [23], [2], [23], [23], [23], [1], [23], [2], [23], [2], [2], [23], [23], [23], [1], [23], [1], [1], [23], [1], [23], [23], [23], [1], [23], [23], [23], [23], [2], [23], [23], [23], [23], [2], [23], [14], [23], [16], [14], [2], [23], [1], [16], [23], [23], [1], [23], [23], [23], [2], [23], [2], [23], [16], [14], [23], [23], [2], [23], [14], [23], [2], [23], [23], [1], [23], [23], [23], [23], [23], [2], [23], [2], [2], [23], [23], [23], [2], [10], [10], [23], [10], [12], [10], [10], [23], [10], [10], [10], [4], [10], [10], [14], [10], [1], [2], [10], [16], [5], [23], [4], [2], [23], [2], [23], [23], [1], [23], [23], [23], [2], [23], [23], [2], [12], [23], [2], [23], [23], [23], [2], [12], [2], [2], [2], [23], [23], [2], [1], [23], [23], [1], [23], [2], [23], [2], [23], [23], [2], [2], [23], [23], [23], [23], [1], [23], [2], [2], [2], [23], [23], [15], [23], [23], [23], [23], [23], [10], [16], [10], [23], [14], [10], [23], [2], [2], [2], [2], [23], [2], [1], [23], [10], [2], [2], [2], [2], [2], [2], [23], [2], [12], [23], [23], [23], [2], [23], [14], [23], [10], [6], [23], [23], [23], [2], [23], [23], [23], [2], [23], [23], [23], [23], [1], [23], [16], [23], [2], [23], [10], [23], [2], [12], [2], [23], [12], [2], [23], [23], [23], [23], [2], [23], [2], [2], [2], [23], [2], [2], [23], [23], [2], [2], [2], [2], [2], [23], [23], [2], [23], [23], [2], [23], [2], [2], [23], [23], [23], [23], [2], [23], [2], [23], [2], [12], [23], [2], [23], [2], [12], [23], [16], [14], [1], [23], [2], [23], [15], [9], [14], [2], [23], [14], [2], [23], [14], [2], [23], [2], [16], [2], [23], [2], [23], [23], [12], [23], [23], [12], [2], [2], [2], [2], [2], [23], [12], [1], [2], [2], [2], [2], [23], [23], [10], [10], [23], [23], [23], [2], [23], [14], [23], [23], [2], [12], [23], [23], [23], [23], [10], [14], [14], [14], [14], [23], [23], [23], [23], [23], [2], [23], [10], [23], [23], [10], [2], [23], [23], [23], [10], [2], [5], [23], [23], [23], [2], [12], [23], [23], [23], [2], [12], [14], [11], [23], [8], [2], [23], [2], [23], [23], [9], [23], [23], [2], [23], [2], [16], [2], [2], [12], [2], [2], [23], [12], [23], [23], [23], [2], [2], [14], [14], [23], [2], [2], [2], [2], [23], [2], [1], [1], [23], [23], [23], [12], [2], [23], [9], [2], [23], [1], [23], [1], [23], [23], [15], [2], [23], [10], [14], [23], [23], [2], [23], [23], [16], [2], [2], [5], [16], [23], [2], [2], [23], [23], [2], [2], [14], [23], [23], [23], [2], [1], [23], [2], [2], [23], [23], [23], [23], [2], [23], [2], [23], [23], [23], [23], [23], [2], [2], [14], [23], [23], [23], [16], [2], [23], [2], [2], [2], [2], [23], [23], [23], [1], [23], [2], [23], [2], [2], [12], [14], [23], [2], [2], [23], [23], [14], [2], [9], [23], [23], [2], [2], [23], [2], [23], [2], [23], [23], [23], [12], [2], [14], [10], [2], [10], [10], [1], [24], [23], [2], [2], [23], [23], [2], [23], [14], [23], [2], [23], [23], [2], [2], [23], [1], [2], [23], [23], [23], [2], [23], [23], [2], [23], [23], [23], [23], [23], [23], [8], [2], [23], [2], [23], [23], [23], [23], [23], [23], [23], [1], [2], [23], [23], [2], [2], [23], [2], [23], [2], [23], [23], [23], [23], [2], [23], [23], [12], [2], [23], [2], [23], [23], [23], [2], [23], [23], [2], [23], [23], [23], [23], [12], [2], [23], [2], [23], [23], [23], [2], [23], [23], [23], [2], [2], [2], [19], [2], [2], [10], [23], [23], [23], [2], [23], [2], [10], [2], [15], [2], [11], [23], [23], [6], [2], [2], [2], [23], [2], [5], [23], [23], [23], [23], [2], [2], [23], [23], [23], [2], [23], [2], [9], [23], [23], [17], [23], [23], [23], [23], [23], [23], [23], [23], [2], [23], [2], [2], [2], [23], [21], [2], [2], [23], [1], [23], [2], [23], [16], [23], [2], [2], [1], [23], [23], [2], [2], [23], [2], [23], [23], [2], [2], [23], [23], [23], [2], [2], [23], [2], [2], [23], [2], [23], [23], [14], [23], [23], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [23], [23], [23], [23], [2], [23], [23], [2], [23], [16], [23], [23], [23], [2], [2], [23], [2], [2], [1], [23], [23], [2], [12], [2], [23], [4], [23], [2], [2], [23], [23], [2], [2], [6], [23], [23], [23], [2], [12], [23], [14], [2], [2], [2], [2], [2], [16], [2], [23], [23], [2], [2], [23], [2], [23], [2], [23], [2], [2], [14], [23], [2], [23], [2], [2], [2], [23], [2], [2], [4], [2], [2], [23], [2], [15], [2], [2], [23], [2], [2], [23], [12], [23], [23], [2], [2], [2], [23], [23], [2], [23], [23], [23], [2], [2], [2], [21], [2], [23], [2], [23], [23], [2], [23], [1], [2], [2], [2], [2], [14], [2], [23], [2], [23], [2], [23], [2], [2], [23], [23], [23], [2], [23], [2], [23], [2], [23], [23], [2], [2], [23], [1], [23], [1], [2], [23], [23], [23], [23], [23], [2], [23], [2], [2], [23], [23], [2], [23], [1], [23], [23], [1], [2], [2], [14], [2], [23], [23], [2], [23], [23], [2], [7], [3], [23], [2], [23], [13], [23], [23], [23], [2], [2], [2], [23], [23], [23], [2], [23], [23], [23], [2], [23], [23], [16], [12], [2], [23], [1], [2], [2], [2], [23], [23], [2], [2], [23], [2], [2], [2], [23], [23], [23], [23], [23], [23], [23], [2], [23], [16], [23], [23], [23], [23], [2], [2], [2], [2], [23], [2], [23], [2], [23], [2], [23], [23], [23], [2], [23], [2], [2], [23], [2], [23], [23], [2], [23], [16], [2], [2], [23], [23], [2], [23], [23], [23], [2], [2], [23], [23], [23], [23], [23], [23], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [14], [2], [23], [23], [23], [2], [2], [23], [23], [2], [23], [2], [2], [23], [23], [2], [12], [14], [23], [23], [14], [2], [2], [23], [23], [2], [2], [2], [1], [2], [2], [2], [23], [2], [2], [23], [14], [23], [2], [23], [23], [2], [23], [14], [2], [2], [23], [2], [23], [23], [23], [23], [2], [2], [2], [23], [23], [2], [2], [2], [23], [2], [2], [23], [2], [23], [2], [2], [23], [23], [23], [2], [23], [16], [2], [2], [2], [2], [2], [23], [23], [23], [2], [15], [2], [23], [21], [23], [2], [2], [23], [23], [23], [23], [23], [2], [23], [2], [14], [2], [23], [2], [23], [23], [2], [2], [2], [23], [23], [2], [2], [23], [23], [23], [23], [2], [23], [2], [23], [23], [2], [23], [2], [2], [23], [2], [23], [2], [23], [23], [23], [23], [5], [2], [23], [2], [23], [23], [23], [2], [23], [23], [23], [23], [15], [23], [23], [23], [23], [23], [23], [23], [2], [23], [23], [1], [23], [23], [2], [2], [5], [23], [14], [2], [2], [2], [23], [2], [2], [2], [21], [23], [23], [2], [2], [23], [2], [2], [12], [23], [23], [2], [1], [2], [23], [2], [23], [2], [14], [23], [12], [23], [2], [23], [23], [2], [23], [12], [23], [23], [23], [23], [14], [2], [2], [23], [23], [23], [23], [23], [2], [2], [14], [23], [23], [23], [23], [16], [23], [2], [23], [2], [23], [23], [2], [23], [23], [2], [23], [15], [23], [2], [23], [14], [23], [1], [23], [23], [2], [23], [23], [2], [2], [23], [23], [23], [23], [2], [14], [2], [23], [23], [2], [23], [2], [23], [23], [14], [23], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [12], [23], [23], [2], [2], [23], [2], [23], [2], [23], [23], [23], [2], [23], [23], [2], [1], [23], [12], [23], [2], [23], [23], [14], [23], [1], [23], [2], [2], [2], [2], [23], [14], [1], [23], [2], [23], [2], [2], [2], [23], [2], [2], [23], [2], [23], [2], [23], [2], [2], [14], [23], [23], [23], [2], [23], [23], [23], [2], [23], [23], [2], [14], [2], [23], [23], [23], [2], [23], [23], [14], [23], [23], [23], [23], [2], [2], [23], [23], [2], [23], [16], [23], [23], [2], [23], [23], [23], [23], [23], [2], [2], [2], [23], [2], [10], [2], [23], [23], [5], [23], [2], [23], [2], [2], [23], [15], [14], [2], [2], [23], [23], [14], [23], [23], [14], [23], [2], [2], [23], [23], [14], [1], [10], [23], [10], [23], [10], [23], [10], [2], [23], [10], [14], [10], [23], [23], [2], [2], [2], [10], [10], [10], [14], [10], [23], [2], [14], [2], [2], [2], [23], [14], [2], [2], [23], [2], [2], [2], [23], [23], [23], [23], [2], [23], [2], [23], [23], [14], [12], [14], [2], [2], [23], [23], [23], [23], [2], [23], [23], [23], [23], [2], [16], [23], [23], [14], [2], [2], [23], [23], [23], [2], [23], [14], [23], [23], [23], [2], [23], [2], [23], [2], [23], [5], [2], [2], [2], [14], [2], [23], [23], [23], [23], [2], [23], [23], [23], [23], [23], [14], [23], [2], [14], [2], [9], [2], [23], [2], [23], [23], [23], [23], [23], [2], [2], [23], [23], [2], [23], [2], [23], [23], [2], [23], [23], [9], [12], [23], [16], [23], [2], [23], [23], [23], [1], [23], [2], [23], [1], [23], [23], [2], [2], [14], [16], [2], [2], [23], [23], [2], [23], [14], [23], [23], [2], [2], [2], [23], [23], [2], [2], [23], [2], [23], [2], [10], [2], [23], [14], [16], [2], [23], [23], [2], [23], [14], [23], [23], [14], [2], [23], [2], [23], [23], [23], [2], [23], [23], [9], [23], [23], [23], [16], [2], [2], [23], [2], [23], [16], [2], [2], [15], [2], [23], [2], [23], [1], [2], [1], [2], [23], [23], [23], [23], [2], [9], [23], [23], [23], [2], [2], [2], [2], [2], [2], [23], [1], [2], [23], [2], [2], [10], [16], [23], [23], [23], [2], [2], [16], [23], [16], [23], [2], [12], [2], [2], [2], [23], [23], [2], [23], [2], [23], [23], [23], [23], [23], [2], [2], [23], [23], [23], [23], [2], [2], [23], [23], [2], [2], [23], [23], [23], [23], [23], [23], [23], [23], [23], [2], [2], [2], [1], [2], [23], [23], [23], [14], [23], [23], [23], [14], [2], [23], [2], [12], [14], [16], [2], [23], [2], [23], [23], [23], [14], [14], [2], [23], [12], [2], [2], [2], [12], [12], [23], [12], [2], [23], [2], [17], [23], [23], [23], [23], [1], [1], [23], [23], [23], [23], [2], [10], [23], [23], [2], [23], [23], [23], [2], [23], [23], [23], [23], [16], [23], [23], [23], [23], [2], [23], [14], [23], [2], [2], [14], [23], [23], [2], [23], [23], [2], [23], [23], [2], [14], [16], [23], [2], [1], [23], [23], [23], [2], [23], [23], [18], [2], [23], [23], [23], [23], [2], [1], [23], [23], [23], [23], [23], [2], [23], [2], [23], [23], [23], [23], [23], [2], [2], [23], [23], [14], [23], [2], [14], [23], [2], [2], [15], [23], [2], [23], [4], [2], [23], [15], [23], [14], [2], [15], [23], [23], [6], [2], [23], [2], [2], [23], [2], [23], [21], [2], [23], [23], [10], [23], [2], [10], [2], [23], [2], [2], [23], [2], [2], [23], [23], [23], [17], [23], [2], [2], [2], [2], [23], [23], [2], [14], [23], [14], [23], [23], [18], [2], [2], [14], [2], [14], [6], [23], [2], [2], [2], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [9], [2], [23], [16], [23], [2], [23], [2], [23], [23], [23], [2], [2], [2], [2], [5], [2], [15], [2], [23], [23], [12], [23], [23], [2], [12], [2], [3], [2], [23], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [15], [23], [2], [2], [23], [2], [2], [2], [23], [23], [2], [2], [2], [2], [23], [2], [2], [22], [2], [23], [2], [2], [2], [2], [15], [15], [2], [23], [23], [23], [16], [23], [15], [23], [2], [14], [2], [15], [2], [23], [23], [23], [1], [14], [0], [23], [2], [23], [2], [2], [2], [12], [23], [2], [15], [2], [23], [2], [23], [2], [23], [14], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [14], [23], [2], [23], [23], [2], [23], [23], [23], [2], [23], [2], [23], [2], [2], [23], [9], [2], [23], [23], [23], [2], [23], [23], [2], [23], [23], [1], [16], [2], [2], [23], [23], [23], [2], [9], [17], [23], [23], [23], [23], [23], [23], [2], [2], [2], [23], [2], [23], [2], [2], [16], [2], [23], [23], [23], [1], [2], [23], [1], [2], [2], [2], [23], [2], [2], [1], [2], [12], [23], [14], [12], [2], [23], [23], [23], [2], [2], [1], [2], [2], [14], [2], [2], [2], [2], [2], [14], [23], [23], [23], [23], [2], [2], [23], [23], [25], [2], [2], [14], [23], [23], [17], [2], [2], [2], [10], [23], [8], [23], [23], [2], [2], [23], [23], [16], [23], [2], [23], [2], [23], [23], [2], [2], [23], [23], [14], [9], [2], [2], [2], [1], [23], [2], [2], [9], [23], [2], [23], [23], [2], [8], [4], [2], [23], [23], [23], [2], [2], [2], [23], [23], [23], [23], [2], [5], [2], [2], [2], [2], [2], [2], [2], [23], [23], [23], [2], [8], [23], [2], [4], [3], [23], [23], [23], [23], [2], [23], [1], [10], [23], [16], [23], [10], [16], [23], [2], [2], [2], [23], [9], [2], [14], [23], [12], [2], [1], [23], [2], [2], [2], [2], [2], [2], [2], [16], [2], [23], [2], [23], [2], [2], [9], [23], [9], [2], [23], [23], [23], [2], [23], [23], [2], [23], [23], [2], [1], [12], [14], [23], [2], [9], [14], [7], [23], [23], [23], [15], [2], [12], [10], [23], [12], [2], [1], [2], [23], [2], [9], [23], [14], [12], [16], [2], [14], [12], [23], [5], [23], [20], [2], [2], [2], [23], [2], [23], [2], [2], [23], [23], [23], [23], [23], [23], [2], [1], [2], [23], [2], [23], [2], [12], [2], [23], [2], [2], [23], [1], [12], [1], [2], [23], [12], [23], [1], [2], [23], [2], [14], [2], [2], [23], [9], [2], [23], [1], [23], [23], [23], [2], [15], [2], [23], [8], [14], [23], [23], [10], [10], [23], [15], [23], [23], [23], [23], [23], [2], [23], [23], [16], [23], [2], [16], [23], [2], [10], [2], [2], [9], [2], [23], [2], [2], [12], [12], [23], [23], [2], [2], [23], [4], [2], [23], [4], [23], [23], [23], [2], [14], [2], [14], [23], [2], [23], [23], [23], [23], [23], [2], [23], [2], [2], [23], [23], [1], [4], [2], [2], [23], [1], [4], [23], [23], [23], [2], [2], [10], [10], [2], [2], [10], [23], [23], [12], [23], [23], [2], [2], [23], [23], [12], [23], [2], [23], [23], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [13], [23], [2], [16], [23], [2], [2], [12], [23], [2], [23], [23], [2], [2], [23], [23], [2], [23], [2], [23], [23], [23], [23], [23], [23], [14], [23], [23], [23], [23], [2], [2], [12], [23], [12], [14], [2], [2], [2], [23], [2], [23], [23], [12], [2], [12], [2], [1], [2], [23], [23], [23], [23], [14], [23], [2], [23], [23], [2], [1], [2], [23], [23], [2], [23], [2], [2], [2], [2], [23], [23], [14], [23], [23], [2], [2], [2], [23], [2], [10], [23], [14], [4], [23], [2], [2], [2], [16], [19], [2], [4], [2], [23], [23], [10], [23], [12], [2], [23], [2], [4], [23], [23], [4], [4], [23], [2], [23], [23], [2], [23], [24], [2], [2], [23], [23], [16], [23], [23], [2], [23], [2], [2], [2], [2], [2], [23], [2], [23], [2], [23], [23], [16], [1], [1], [1], [2], [23], [23], [23], [12], [2], [23], [23], [23], [23], [2], [2], [8], [2], [2], [23], [2], [23], [2], [2], [2], [2], [23], [1], [8], [23], [14], [23], [2], [23], [2], [10], [23], [5], [16], [23], [14], [2], [1], [23], [23], [2], [2], [12], [23], [23], [2], [19], [23], [23], [17], [2], [18], [23], [2], [7], [15], [23], [23], [2], [14], [23], [2], [24], [2], [14], [12], [14], [1], [23], [2], [14], [23], [23], [14], [23], [1], [9], [10], [2], [2], [21], [2], [2], [2], [2], [2], [12], [23], [2], [2], [12], [14], [2], [12], [23], [16], [23], [12], [2], [2], [23], [23], [2], [23], [23], [23], [2], [23], [12], [23], [14], [23], [2], [14], [2], [2], [2], [2], [23], [2], [23], [14], [23], [2], [23], [2], [10], [2], [10], [2], [23], [2], [23], [2], [12], [23], [23], [23], [2], [2], [23], [2], [23], [21], [23], [1], [23], [14], [2], [23], [2], [2], [12], [2], [23], [2], [2], [12], [23], [2], [23], [12], [23], [23], [23], [23], [2], [2], [2], [2], [2], [23], [2], [23], [2], [1], [23], [14], [23], [23], [23], [13], [12], [2], [2], [23], [23], [23], [2], [2], [15], [15], [2], [14], [23], [2], [23], [23], [16], [23], [14], [23], [23], [23], [23], [23], [23], [23], [4], [2], [2], [23], [23], [2], [1], [1], [23], [23], [23], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [2], [23], [23], [10], [23], [2], [23], [23], [2], [2], [14], [23], [2], [1], [2], [2], [2], [23], [23], [2], [2], [2], [23], [2], [23], [23], [2], [23], [23], [23], [2], [23], [23], [0], [2], [2], [23], [2], [10], [8], [23], [2], [10], [23], [10], [23], [16], [23], [2], [23], [2], [2], [2], [23], [14], [2], [1], [2], [12], [2], [23], [2], [0], [23], [23], [2], [23], [23], [23], [2], [14], [2], [10], [2], [14], [23], [2], [14], [2], [2], [23], [15], [12], [2], [1], [2], [2], [23], [14], [23], [12], [2], [2], [23], [10], [23], [15], [2], [2], [2], [2], [23], [23], [23], [16], [23], [2], [2], [23], [5], [23], [23], [23], [14], [23], [2], [10], [10], [2], [2], [2], [3], [23], [10], [23], [23], [2], [2], [2], [2], [2], [2], [10], [10], [10], [2], [23], [10], [2], [2], [2], [14], [2], [23], [12], [23], [23], [23], [14], [7], [23], [23], [2], [23], [2], [23], [2], [2], [23], [23], [23], [14], [2], [15], [23], [2], [23], [2], [23], [14], [23], [14], [15], [23], [2], [14], [23], [14], [2], [14], [23], [23], [2], [2], [1], [14], [2], [14], [24], [23], [23], [16], [2], [23], [23], [23], [2], [23], [14], [2], [2], [23], [23], [15], [23], [23], [14], [14], [23], [23], [14], [2], [23], [2], [23], [2], [23], [23], [16], [21], [23], [2], [2], [23], [2], [23], [12], [2], [23], [2], [23], [23], [2], [12], [2], [23], [2], [2], [23], [9], [2], [2], [7], [2], [2], [23], [23], [2], [2], [3], [2], [2], [10], [23], [2], [15], [2], [23], [2], [2], [23], [23], [2], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [23], [23], [2], [23], [23], [2], [16], [2], [2], [14], [2], [2], [2], [2], [23], [23], [2], [1], [23], [23], [23], [12], [23], [0], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [23], [2], [23], [23], [23], [14], [2], [23], [9], [23], [23], [2], [2], [2], [2], [2], [2], [23], [23], [12], [12], [23], [23], [2], [2], [2], [14], [23], [23], [2], [2], [12], [2], [2], [23], [23], [0], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [23], [2], [16], [1], [1], [0], [23], [2], [2], [2], [23], [0], [2], [2], [2], [2], [2], [23], [23], [23], [23], [23], [2], [2], [10], [2], [2], [4], [2], [23], [10], [2], [12], [10], [2], [15], [14], [2], [10], [23], [23], [2], [15], [2], [23], [23], [12], [2], [23], [9], [23], [2], [14], [12], [23], [6], [23], [12], [2], [23], [2], [23], [2], [10], [23], [2], [23], [2], [2], [2], [2], [2], [23], [16], [2], [14], [23], [2], [2], [2], [1], [10], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [14], [2], [23], [1], [2], [3], [2], [2], [2], [2], [14], [11], [2], [2], [2], [2], [2], [23], [2], [8], [7], [23], [2], [2], [1], [2], [2], [2], [14], [14], [2], [23], [23], [23], [4], [12], [12], [23], [2], [2], [23], [2], [23], [23], [23], [2], [23], [2], [1], [2], [2], [2], [23], [24], [23], [23], [2], [14], [12], [23], [2], [23], [10], [8], [24], [23], [23], [2], [2], [2], [2], [2], [2], [23], [2], [15], [23], [2], [2], [2], [23], [2], [16], [2], [23], [23], [2], [2], [2], [23], [2], [14], [23], [5], [2], [14], [23], [14], [23], [2], [2], [2], [12], [23], [2], [2], [23], [2], [2], [2], [23], [10], [2], [23], [6], [2], [2], [14], [2], [15], [14], [2], [16], [2], [2], [23], [2], [1], [2], [2], [2], [23], [2], [2], [14], [1], [2], [23], [23], [2], [2], [23], [6], [23], [23], [23], [15], [16], [14], [17], [23], [10], [23], [2], [14], [23], [23], [2], [23], [2], [2], [2], [23], [2], [2], [23], [2], [2], [14], [4], [2], [1], [2], [12], [2], [2], [2], [2], [2], [23], [2], [23], [2], [15], [2], [23], [2], [2], [23], [12], [2], [2], [2], [23], [23], [2], [23], [2], [2], [2], [9], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [14], [23], [15], [23], [2], [23], [9], [2], [2], [23], [23], [2], [21], [23], [2], [2], [2], [2], [2], [23], [14], [12], [14], [2], [9], [1], [23], [23], [23], [2], [2], [21], [23], [2], [2], [2], [14], [2], [23], [2], [2], [2], [1], [23], [23], [2], [2], [23], [14], [2], [2], [2], [10], [2], [2], [2], [23], [23], [14], [23], [23], [23], [10], [23], [14], [23], [2], [2], [2], [14], [2], [10], [16], [2], [12], [2], [1], [2], [23], [2], [23], [23], [23], [10], [2], [2], [6], [2], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [10], [2], [23], [2], [23], [2], [2], [23], [2], [23], [14], [14], [2], [2], [23], [2], [12], [2], [12], [23], [12], [23], [2], [23], [2], [2], [23], [2], [23], [23], [2], [1], [2], [2], [2], [23], [10], [23], [23], [23], [2], [23], [2], [2], [23], [2], [2], [2], [2], [16], [1], [23], [15], [23], [2], [1], [2], [2], [2], [23], [23], [2], [2], [14], [16], [12], [10], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [23], [23], [2], [2], [2], [23], [23], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [23], [2], [1], [23], [15], [23], [2], [23], [23], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [14], [2], [10], [2], [23], [2], [2], [23], [10], [2], [2], [10], [2], [23], [16], [23], [16], [24], [2], [2], [2], [23], [2], [23], [10], [23], [23], [23], [2], [14], [2], [2], [23], [2], [2], [2], [2], [23], [23], [23], [14], [0], [2], [23], [23], [12], [2], [2], [2], [14], [23], [23], [10], [2], [10], [2], [2], [2], [2], [14], [2], [2], [23], [2], [23], [2], [2], [23], [23], [23], [23], [2], [23], [2], [14], [2], [23], [23], [2], [2], [23], [23], [2], [23], [2], [2], [2], [23], [23], [2], [2], [12], [9], [2], [23], [2], [2], [15], [2], [2], [18], [2], [2], [23], [2], [23], [23], [2], [23], [23], [2], [2], [23], [23], [2], [23], [2], [2], [2], [2], [15], [23], [2], [23], [2], [12], [14], [2], [8], [2], [2], [8], [23], [10], [23], [2], [14], [2], [2], [23], [1], [2], [2], [2], [2], [2], [2], [2], [23], [2], [1], [15], [10], [10], [2], [2], [23], [2], [2], [23], [23], [2], [2], [2], [2], [2], [16], [2], [2], [23], [0], [15], [14], [23], [23], [17], [2], [0], [23], [14], [2], [2], [14], [2], [2], [2], [14], [2], [23], [14], [2], [2], [2], [1], [2], [23], [2], [2], [2], [2], [14], [2], [2], [14], [2], [23], [23], [23], [14], [2], [12], [14], [12], [23], [2], [2], [2], [2], [23], [2], [23], [14], [12], [23], [23], [1], [23], [14], [2], [2], [23], [2], [2], [12], [23], [14], [2], [2], [12], [23], [2], [15], [2], [8], [2], [2], [2], [2], [12], [2], [2], [2], [1], [23], [15], [23], [2], [2], [23], [23], [2], [2], [12], [2], [23], [2], [12], [8], [2], [12], [23], [2], [10], [2], [23], [12], [2], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [2], [15], [2], [23], [23], [2], [2], [2], [4], [2], [23], [14], [2], [23], [23], [2], [14], [14], [2], [2], [2], [23], [2], [23], [23], [2], [14], [14], [4], [2], [3], [2], [2], [23], [0], [2], [2], [8], [23], [2], [23], [0], [2], [8], [15], [2], [10], [10], [10], [10], [23], [10], [2], [15], [23], [10], [23], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [10], [23], [2], [2], [12], [12], [23], [2], [2], [2], [2], [2], [23], [10], [23], [2], [23], [23], [15], [2], [23], [2], [2], [23], [2], [23], [2], [2], [2], [23], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [16], [10], [10], [23], [23], [2], [2], [23], [15], [2], [23], [23], [23], [2], [10], [14], [2], [12], [2], [1], [23], [12], [2], [14], [23], [23], [14], [23], [23], [2], [2], [23], [2], [2], [23], [14], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [14], [2], [2], [10], [2], [2], [2], [23], [2], [2], [2], [2], [14], [23], [23], [2], [2], [14], [23], [2], [2], [2], [2], [10], [2], [23], [2], [14], [23], [2], [2], [2], [2], [23], [10], [14], [2], [23], [2], [2], [23], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [2], [1], [2], [23], [2], [2], [2], [2], [2], [12], [2], [23], [23], [15], [23], [23], [2], [2], [23], [14], [23], [23], [23], [2], [2], [2], [1], [2], [23], [23], [2], [23], [2], [2], [2], [2], [2], [2], [15], [2], [23], [1], [16], [2], [23], [23], [23], [1], [2], [2], [2], [23], [21], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [12], [23], [23], [2], [2], [2], [2], [2], [2], [10], [14], [23], [2], [15], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [7], [12], [23], [12], [2], [2], [2], [23], [14], [2], [23], [23], [2], [23], [25], [23], [23], [14], [2], [2], [23], [14], [23], [23], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [17], [23], [2], [2], [15], [23], [2], [2], [2], [14], [21], [2], [14], [23], [23], [23], [2], [2], [23], [1], [16], [2], [23], [2], [2], [23], [23], [2], [2], [23], [2], [2], [23], [2], [2], [15], [2], [2], [2], [2], [16], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [23], [2], [2], [2], [23], [2], [2], [19], [2], [23], [2], [12], [23], [2], [2], [2], [23], [2], [2], [2], [1], [2], [23], [2], [0], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [16], [2], [23], [23], [9], [2], [4], [2], [23], [23], [2], [1], [2], [23], [23], [2], [2], [2], [5], [12], [16], [2], [2], [2], [2], [2], [17], [2], [23], [2], [14], [23], [1], [2], [23], [2], [2], [2], [2], [2], [12], [2], [2], [2], [23], [15], [23], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [16], [2], [2], [2], [2], [23], [2], [23], [1], [14], [2], [4], [12], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [23], [2], [14], [2], [23], [23], [2], [15], [2], [23], [14], [23], [2], [14], [16], [2], [2], [2], [23], [23], [14], [2], [23], [2], [2], [2], [2], [2], [25], [10], [23], [14], [2], [10], [10], [10], [10], [2], [23], [23], [14], [23], [2], [23], [2], [2], [23], [9], [2], [2], [23], [2], [2], [2], [2], [23], [23], [2], [23], [21], [2], [23], [23], [2], [23], [23], [2], [23], [23], [15], [2], [2], [23], [2], [2], [2], [2], [15], [23], [23], [1], [0], [2], [14], [24], [23], [2], [2], [23], [1], [23], [2], [23], [23], [14], [2], [2], [2], [1], [23], [2], [2], [2], [2], [14], [2], [2], [23], [2], [2], [2], [1], [2], [23], [2], [0], [2], [2], [2], [0], [2], [23], [23], [2], [2], [2], [23], [15], [2], [2], [2], [2], [10], [2], [23], [12], [2], [2], [23], [2], [23], [23], [1], [24], [2], [23], [14], [2], [2], [12], [2], [16], [2], [2], [2], [2], [2], [2], [14], [2], [2], [12], [2], [16], [2], [0], [2], [23], [2], [23], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [14], [2], [2], [2], [16], [23], [2], [2], [23], [2], [23], [2], [14], [2], [2], [23], [23], [2], [5], [15], [23], [2], [2], [16], [2], [14], [2], [2], [1], [23], [23], [2], [2], [2], [2], [10], [2], [2], [23], [2], [2], [2], [23], [2], [2], [23], [2], [14], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [15], [16], [2], [2], [2], [2], [2], [23], [2], [2], [23], [14], [14], [2], [2], [2], [2], [2], [2], [2], [5], [23], [16], [23], [2], [10], [23], [1], [2], [23], [2], [5], [10], [2], [23], [16], [2], [2], [14], [2], [2], [23], [23], [2], [2], [4], [16], [23], [23], [23], [2], [2], [2], [23], [2], [2], [12], [2], [16], [2], [2], [2], [2], [2], [4], [2], [2], [2], [2], [23], [2], [23], [2], [23], [23], [23], [23], [10], [2], [2], [14], [2], [23], [23], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [23], [23], [23], [14], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [16], [2], [2], [16], [2], [23], [6], [23], [2], [10], [2], [2], [2], [14], [5], [23], [15], [2], [2], [23], [2], [23], [23], [2], [15], [0], [2], [2], [21], [2], [2], [2], [1], [2], [15], [12], [2], [2], [2], [23], [23], [16], [14], [2], [2], [8], [12], [15], [23], [2], [12], [2], [2], [4], [2], [1], [2], [2], [21], [2], [24], [23], [23], [2], [14], [23], [2], [12], [23], [4], [2], [16], [2], [12], [2], [2], [23], [2], [9], [2], [2], [23], [14], [2], [2], [23], [2], [2], [2], [18], [2], [2], [23], [2], [2], [14], [16], [23], [2], [2], [23], [15], [23], [23], [2], [1], [23], [23], [2], [2], [23], [23], [2], [2], [2], [14], [16], [2], [2], [2], [0], [2], [12], [12], [2], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [0], [2], [0], [2], [2], [2], [14], [2], [1], [23], [2], [2], [14], [2], [16], [4], [23], [2], [2], [23], [2], [16], [14], [2], [10], [12], [2], [12], [23], [2], [23], [2], [2], [0], [2], [23], [1], [2], [2], [2], [2], [16], [14], [14], [2], [2], [14], [14], [2], [2], [23], [14], [23], [14], [2], [23], [23], [14], [2], [14], [2], [2], [2], [21], [2], [2], [2], [23], [12], [2], [2], [12], [2], [12], [23], [2], [12], [23], [2], [2], [2], [24], [2], [23], [14], [2], [12], [23], [2], [2], [2], [2], [10], [23], [2], [2], [2], [14], [2], [2], [2], [23], [2], [14], [23], [2], [2], [2], [23], [2], [2], [0], [2], [2], [14], [14], [2], [2], [2], [2], [2], [2], [2], [23], [21], [2], [23], [2], [2], [23], [2], [1], [23], [2], [14], [23], [23], [16], [2], [25], [2], [2], [23], [23], [23], [2], [15], [23], [23], [23], [15], [15], [2], [2], [2], [23], [23], [23], [2], [2], [2], [2], [23], [2], [2], [2], [10], [23], [2], [4], [2], [12], [23], [12], [12], [23], [2], [2], [23], [23], [12], [2], [15], [23], [2], [23], [2], [16], [23], [23], [23], [15], [2], [2], [23], [23], [2], [23], [2], [2], [14], [14], [2], [23], [4], [2], [1], [23], [2], [2], [23], [23], [2], [2], [23], [23], [23], [12], [2], [2], [23], [23], [2], [2], [2], [2], [12], [23], [23], [2], [23], [23], [2], [2], [2], [23], [1], [2], [2], [23], [23], [2], [2], [8], [2], [2], [2], [2], [2], [2], [23], [23], [23], [2], [2], [2], [2], [2], [23], [20], [2], [16], [22], [2], [2], [23], [23], [2], [14], [23], [23], [2], [23], [2], [2], [23], [2], [2], [2], [2], [2], [12], [0], [2], [2], [2], [2], [10], [23], [2], [12], [23], [12], [23], [12], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [12], [15], [16], [23], [2], [2], [14], [23], [12], [15], [2], [14], [23], [2], [23], [2], [2], [23], [23], [23], [2], [2], [23], [23], [2], [15], [23], [2], [23], [2], [2], [23], [23], [2], [2], [23], [2], [2], [2], [12], [2], [2], [2], [2], [23], [23], [23], [10], [2], [2], [2], [23], [2], [2], [2], [23], [2], [23], [12], [2], [4], [2], [23], [2], [2], [23], [14], [23], [15], [2], [2], [10], [10], [2], [14], [2], [2], [23], [23], [2], [2], [1], [2], [2], [1], [23], [2], [2], [0], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [23], [12], [23], [23], [2], [2], [23], [2], [2], [2], [2], [2], [2], [23], [2], [0], [23], [23], [2], [2], [23], [23], [23], [2], [23], [2], [2], [23], [2], [2], [12], [2], [2], [23], [23], [16], [0], [6], [1], [2], [23], [2], [2], [23], [2], [12], [14], [2], [9], [23], [2], [2], [2], [23], [14], [2], [2], [2], [2], [7], [2], [23], [2], [2], [15], [2], [2], [2], [14], [2], [23], [23], [2], [2], [23], [1], [2], [15], [2], [23], [1], [2], [15], [14], [1], [2], [2], [15], [23], [1], [2], [23], [23], [2], [2], [16], [16], [2], [2], [2], [16], [23], [2], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [1], [2], [10], [14], [2], [14], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [2], [14], [9], [23], [2], [2], [9], [2], [10], [2], [16], [23], [2], [12], [2], [23], [23], [2], [2], [2], [4], [23], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [2], [15], [2], [14], [2], [23], [2], [2], [15], [23], [14], [2], [16], [2], [2], [2], [2], [1], [2], [14], [2], [2], [2], [2], [2], [23], [23], [2], [2], [23], [2], [16], [23], [2], [23], [2], [2], [2], [2], [10], [2], [23], [2], [2], [1], [16], [2], [15], [2], [4], [2], [2], [23], [12], [2], [6], [2], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [1], [14], [23], [2], [20], [2], [10], [23], [2], [23], [4], [2], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [0], [23], [2], [2], [23], [10], [0], [23], [2], [14], [2], [2], [2], [23], [2], [2], [23], [23], [14], [2], [23], [23], [2], [23], [2], [2], [2], [15], [10], [23], [2], [2], [9], [2], [16], [16], [14], [23], [23], [2], [2], [2], [14], [1], [2], [5], [2], [14], [2], [1], [2], [1], [2], [2], [15], [2], [2], [2], [4], [16], [2], [2], [2], [14], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [12], [2], [2], [23], [2], [2], [2], [2], [20], [23], [2], [2], [1], [14], [12], [2], [23], [14], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [9], [1], [12], [12], [12], [2], [2], [2], [23], [2], [15], [2], [2], [2], [23], [2], [1], [14], [2], [2], [23], [2], [2], [2], [2], [15], [12], [2], [23], [14], [2], [23], [2], [0], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [23], [23], [2], [14], [2], [14], [2], [2], [12], [2], [2], [2], [2], [2], [23], [0], [14], [14], [2], [2], [23], [14], [16], [2], [0], [2], [14], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [1], [2], [2], [2], [2], [10], [2], [2], [24], [1], [2], [23], [23], [2], [14], [23], [1], [23], [23], [2], [23], [2], [2], [2], [14], [2], [2], [23], [23], [2], [14], [23], [2], [2], [2], [10], [14], [2], [2], [2], [2], [2], [16], [2], [2], [2], [23], [2], [2], [10], [2], [12], [14], [23], [2], [23], [23], [2], [2], [2], [23], [2], [2], [2], [1], [15], [23], [23], [14], [12], [2], [2], [23], [2], [2], [23], [2], [23], [2], [2], [23], [2], [2], [2], [12], [23], [2], [2], [2], [2], [2], [2], [2], [9], [2], [23], [23], [4], [2], [2], [2], [14], [2], [2], [23], [23], [2], [2], [12], [2], [5], [14], [2], [14], [2], [2], [2], [2], [1], [2], [15], [16], [1], [15], [14], [1], [14], [2], [23], [14], [14], [2], [23], [2], [23], [10], [23], [23], [2], [23], [15], [23], [2], [2], [23], [2], [2], [2], [2], [12], [2], [10], [6], [23], [2], [2], [2], [12], [2], [5], [23], [2], [23], [23], [23], [15], [2], [12], [2], [2], [2], [0], [2], [2], [2], [2], [2], [2], [2], [2], [15], [23], [2], [2], [23], [23], [2], [2], [2], [23], [10], [10], [2], [2], [23], [2], [14], [2], [2], [2], [23], [2], [2], [2], [2], [2], [13], [23], [2], [2], [2], [23], [2], [1], [2], [2], [2], [23], [23], [2], [23], [23], [2], [2], [12], [2], [23], [2], [23], [2], [2], [1], [23], [2], [2], [2], [2], [2], [2], [23], [2], [23], [23], [23], [14], [23], [19], [23], [2], [23], [14], [2], [14], [0], [2], [2], [0], [2], [2], [2], [23], [2], [2], [12], [12], [21], [23], [11], [2], [23], [2], [15], [2], [23], [2], [2], [2], [2], [23], [0], [12], [23], [2], [2], [2], [2], [12], [2], [2], [2], [14], [12], [12], [23], [12], [15], [23], [2], [0], [2], [23], [14], [14], [2], [2], [23], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [12], [23], [2], [2], [2], [2], [12], [2], [2], [2], [14], [2], [2], [12], [1], [2], [2], [2], [2], [2], [2], [2], [2], [14], [23], [12], [2], [2], [9], [2], [2], [23], [2], [12], [2], [2], [2], [2], [1], [2], [23], [2], [2], [23], [2], [2], [1], [2], [1], [2], [2], [23], [14], [14], [2], [23], [0], [2], [23], [12], [12], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [1], [2], [2], [10], [2], [0], [2], [23], [2], [23], [2], [2], [5], [23], [2], [2], [2], [2], [10], [23], [23], [23], [2], [23], [2], [14], [21], [2], [23], [2], [23], [0], [2], [23], [2], [14], [14], [23], [2], [0], [8], [2], [23], [14], [12], [2], [2], [14], [2], [2], [2], [14], [15], [23], [23], [23], [23], [23], [0], [2], [10], [10], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [23], [23], [23], [2], [2], [2], [23], [2], [23], [2], [23], [23], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [12], [2], [2], [2], [12], [2], [10], [2], [2], [0], [2], [2], [2], [2], [4], [12], [2], [12], [2], [2], [2], [2], [6], [2], [23], [2], [10], [2], [2], [14], [2], [10], [23], [2], [23], [2], [2], [10], [2], [23], [2], [2], [2], [2], [9], [2], [9], [12], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [12], [16], [2], [2], [23], [3], [2], [2], [2], [14], [2], [14], [2], [2], [2], [23], [10], [10], [23], [10], [2], [14], [10], [2], [15], [2], [2], [2], [2], [2], [0], [14], [2], [16], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [23], [16], [2], [2], [2], [17], [23], [23], [2], [12], [14], [14], [2], [14], [2], [2], [1], [1], [2], [23], [10], [2], [23], [10], [10], [14], [10], [10], [16], [2], [10], [2], [2], [10], [10], [2], [10], [10], [10], [2], [10], [10], [17], [10], [23], [12], [23], [2], [2], [10], [23], [23], [2], [10], [12], [10], [2], [1], [2], [16], [2], [2], [2], [2], [2], [2], [2], [2], [23], [10], [2], [2], [14], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [2], [2], [23], [2], [2], [23], [22], [2], [2], [2], [2], [2], [16], [23], [23], [2], [2], [23], [23], [23], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [9], [2], [14], [2], [2], [2], [2], [2], [2], [12], [2], [14], [1], [2], [0], [23], [2], [23], [2], [15], [2], [2], [2], [23], [16], [12], [2], [2], [2], [10], [2], [23], [2], [2], [2], [23], [23], [2], [14], [2], [2], [2], [2], [2], [2], [1], [14], [2], [2], [2], [8], [23], [2], [2], [12], [23], [12], [23], [2], [23], [2], [23], [12], [2], [2], [2], [2], [2], [2], [23], [2], [23], [15], [14], [2], [2], [1], [2], [23], [2], [23], [2], [23], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [14], [1], [23], [2], [2], [2], [12], [23], [2], [23], [23], [14], [1], [2], [2], [2], [2], [14], [23], [23], [2], [2], [2], [23], [1], [2], [23], [14], [2], [16], [23], [2], [2], [14], [2], [21], [2], [2], [18], [2], [2], [2], [1], [2], [23], [23], [14], [2], [2], [2], [2], [1], [16], [2], [2], [2], [13], [23], [2], [2], [1], [2], [2], [23], [2], [23], [23], [15], [14], [2], [2], [23], [2], [8], [2], [2], [21], [2], [23], [23], [23], [2], [3], [2], [14], [2], [2], [2], [2], [2], [2], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [12], [2], [1], [23], [23], [23], [2], [2], [12], [23], [23], [23], [23], [23], [23], [2], [2], [14], [2], [2], [9], [2], [2], [14], [2], [23], [23], [23], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [23], [23], [0], [15], [0], [23], [23], [2], [2], [23], [10], [23], [23], [23], [12], [2], [15], [2], [2], [23], [23], [23], [2], [23], [2], [23], [2], [0], [23], [14], [2], [2], [23], [0], [1], [23], [16], [23], [15], [23], [12], [4], [23], [2], [2], [2], [1], [2], [23], [2], [2], [2], [1], [2], [23], [2], [2], [2], [2], [2], [2], [2], [14], [0], [1], [8], [20], [2], [15], [2], [2], [2], [2], [2], [23], [2], [2], [23], [16], [23], [23], [2], [23], [23], [12], [2], [2], [1], [2], [23], [2], [8], [2], [23], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [2], [14], [23], [12], [2], [21], [23], [12], [2], [23], [2], [2], [2], [2], [2], [2], [3], [14], [2], [2], [14], [23], [2], [1], [2], [14], [23], [9], [0], [2], [2], [2], [2], [23], [2], [2], [16], [23], [2], [2], [23], [2], [2], [2], [8], [23], [23], [2], [2], [14], [23], [2], [23], [2], [4], [12], [12], [2], [2], [23], [23], [14], [5], [5], [2], [2], [23], [2], [2], [2], [1], [14], [1], [2], [2], [2], [5], [23], [8], [0], [2], [14], [2], [2], [23], [2], [12], [23], [2], [2], [2], [2], [2], [2], [2], [23], [2], [5], [12], [2], [23], [15], [23], [0], [0], [23], [2], [14], [16], [23], [1], [2], [14], [2], [23], [2], [23], [12], [2], [2], [12], [4], [23], [12], [12], [3], [2], [14], [2], [4], [2], [2], [23], [4], [2], [21], [2], [23], [2], [9], [23], [2], [14], [12], [2], [2], [2], [2], [2], [5], [2], [2], [2], [12], [2], [14], [16], [1], [15], [2], [23], [15], [2], [23], [15], [23], [2], [14], [4], [2], [23], [2], [2], [2], [14], [16], [2], [6], [23], [23], [14], [23], [0], [23], [22], [2], [23], [23], [23], [2], [23], [23], [2], [14], [8], [23], [23], [23], [2], [2], [2], [23], [2], [23], [2], [2], [14], [2], [2], [2], [2], [14], [2], [2], [10], [2], [1], [2], [23], [14], [23], [23], [2], [2], [0], [4], [23], [23], [2], [15], [8], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [23], [2], [2], [0], [2], [2], [10], [23], [2], [2], [2], [24], [23], [2], [14], [2], [2], [14], [2], [2], [23], [23], [2], [23], [2], [2], [12], [2], [2], [23], [2], [2], [23], [2], [2], [21], [23], [16], [2], [23], [23], [2], [2], [2], [23], [23], [9], [4], [23], [2], [2], [2], [2], [16], [1], [2], [23], [21], [2], [2], [2], [20], [2], [23], [23], [2], [2], [2], [2], [23], [2], [23], [14], [15], [2], [2], [2], [2], [15], [23], [23], [2], [23], [14], [2], [2], [0], [3], [23], [2], [23], [2], [12], [2], [2], [2], [2], [2], [2], [23], [23], [2], [14], [14], [14], [2], [23], [14], [1], [2], [2], [2], [9], [23], [2], [2], [2], [2], [9], [10], [2], [21], [23], [2], [23], [2], [0], [1], [2], [2], [12], [2], [12], [15], [2], [2], [2], [14], [14], [14], [2], [23], [25], [23], [10], [2], [6], [2], [16], [2], [2], [23], [23], [2], [9], [23], [2], [2], [12], [2], [2], [2], [2], [2], [2], [23], [2], [23], [23], [14], [23], [12], [2], [2], [2], [2], [14], [2], [23], [14], [2], [14], [14], [2], [2], [16], [9], [2], [2], [2], [2], [23], [23], [3], [14], [2], [2], [23], [2], [2], [2], [23], [16], [14], [2], [2], [23], [2], [2], [12], [2], [23], [23], [2], [2], [2], [2], [1], [16], [2], [2], [2], [2], [2], [23], [23], [2], [2], [4], [2], [2], [2], [14], [23], [4], [23], [1], [23], [2], [2], [12], [12], [2], [2], [23], [1], [2], [2], [1], [23], [16], [14], [2], [14], [2], [14], [2], [2], [23], [23], [21], [23], [10], [2], [12], [23], [12], [12], [14], [2], [2], [23], [2], [23], [23], [2], [2], [0], [2], [2], [2], [16], [2], [1], [2], [14], [2], [23], [2], [23], [23], [2], [2], [19], [23], [14], [2], [2], [4], [23], [2], [2], [2], [2], [10], [23], [12], [2], [2], [2], [2], [23], [2], [2], [16], [2], [2], [10], [2], [2], [1], [14], [2], [2], [2], [1], [2], [23], [2], [2], [23], [23], [21], [23], [22], [2], [4], [5], [4], [2], [23], [2], [23], [2], [16], [23], [2], [14], [2], [23], [2], [2], [2], [23], [2], [23], [14], [23], [2], [2], [14], [2], [2], [2], [14], [2], [14], [2], [16], [2], [2], [2], [23], [12], [10], [2], [14], [2], [2], [2], [23], [2], [2], [10], [2], [12], [23], [2], [23], [2], [2], [12], [23], [2], [23], [2], [10], [2], [2], [2], [15], [23], [2], [2], [10], [2], [15], [15], [15], [10], [2], [23], [2], [23], [2], [14], [23], [2], [2], [23], [2], [1], [10], [2], [23], [23], [2], [4], [2], [2], [10], [23], [14], [23], [4], [23], [23], [4], [23], [23], [2], [2], [23], [14], [2], [2], [2], [23], [2], [2], [23], [2], [23], [4], [2], [2], [2], [14], [14], [2], [2], [23], [23], [2], [2], [1], [2], [1], [15], [2], [2], [2], [15], [23], [2], [2], [2], [14], [2], [2], [2], [1], [2], [2], [23], [2], [2], [2], [2], [21], [2], [2], [23], [2], [2], [2], [10], [2], [2], [2], [23], [12], [2], [23], [2], [23], [2], [23], [2], [23], [2], [23], [2], [2], [2], [14], [2], [2], [10], [23], [23], [23], [23], [2], [2], [23], [10], [10], [10], [10], [2], [6], [23], [4], [2], [23], [2], [2], [15], [16], [2], [14], [2], [2], [2], [15], [23], [2], [21], [12], [23], [8], [8], [2], [23], [2], [23], [14], [23], [2], [23], [2], [16], [2], [23], [2], [23], [2], [12], [23], [23], [2], [1], [2], [2], [23], [2], [2], [1], [2], [5], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [10], [23], [9], [2], [23], [23], [2], [2], [15], [12], [23], [2], [2], [15], [23], [2], [2], [2], [2], [2], [23], [12], [23], [14], [23], [2], [2], [4], [2], [2], [2], [2], [2], [12], [2], [14], [2], [14], [2], [14], [2], [23], [2], [2], [1], [23], [23], [2], [2], [12], [8], [23], [2], [2], [2], [1], [9], [15], [4], [2], [2], [2], [23], [2], [2], [2], [1], [2], [2], [23], [2], [2], [2], [16], [14], [24], [4], [23], [2], [2], [23], [14], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [2], [14], [16], [5], [2], [2], [23], [23], [14], [23], [23], [23], [2], [16], [2], [23], [2], [23], [1], [4], [23], [2], [14], [15], [23], [2], [14], [2], [14], [2], [2], [21], [2], [2], [14], [2], [2], [23], [23], [2], [15], [23], [2], [2], [8], [14], [2], [10], [0], [0], [2], [14], [2], [2], [2], [23], [15], [2], [2], [2], [2], [2], [2], [6], [2], [14], [2], [2], [2], [2], [15], [2], [14], [4], [21], [2], [23], [2], [2], [2], [23], [23], [15], [14], [8], [14], [15], [14], [12], [2], [14], [12], [0], [23], [2], [2], [24], [2], [23], [2], [2], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [15], [2], [23], [2], [2], [4], [23], [23], [2], [23], [2], [23], [2], [23], [23], [2], [2], [2], [23], [14], [14], [2], [23], [2], [2], [23], [2], [2], [21], [2], [23], [2], [2], [23], [23], [23], [4], [23], [4], [23], [23], [15], [15], [8], [2], [23], [2], [2], [23], [15], [15], [23], [23], [0], [2], [8], [2], [14], [23], [2], [2], [2], [2], [14], [14], [2], [12], [2], [23], [23], [23], [2], [15], [23], [23], [23], [23], [10], [12], [2], [23], [23], [23], [2], [9], [2], [2], [2], [4], [2], [23], [14], [2], [15], [2], [15], [23], [23], [2], [23], [2], [2], [23], [2], [2], [2], [0], [23], [9], [2], [23], [2], [23], [23], [23], [2], [23], [2], [23], [2], [21], [10], [14], [2], [16], [23], [2], [23], [2], [2], [2], [2], [14], [23], [1], [2], [23], [2], [2], [2], [2], [21], [23], [23], [2], [14], [23], [23], [16], [2], [2], [14], [2], [2], [14], [2], [2], [2], [2], [2], [10], [2], [2], [23], [1], [14], [23], [14], [23], [15], [2], [2], [0], [2], [15], [2], [2], [2], [4], [2], [1], [2], [23], [2], [2], [23], [2], [2], [14], [2], [23], [2], [1], [2], [2], [2], [9], [23], [4], [2], [23], [2], [23], [23], [2], [14], [2], [0], [2], [2], [2], [2], [2], [23], [23], [2], [1], [12], [1], [2], [2], [2], [2], [2], [2], [2], [2], [14], [15], [14], [23], [15], [15], [2], [2], [2], [2], [2], [2], [2], [16], [23], [2], [2], [2], [23], [15], [12], [23], [23], [12], [15], [4], [2], [2], [23], [2], [23], [16], [2], [23], [23], [2], [2], [23], [2], [2], [23], [2], [2], [23], [2], [2], [1], [2], [2], [23], [2], [12], [23], [23], [23], [10], [2], [2], [2], [2], [2], [1], [2], [23], [2], [2], [14], [2], [2], [21], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [16], [2], [23], [2], [2], [2], [2], [14], [2], [2], [14], [23], [2], [14], [8], [14], [23], [2], [2], [2], [1], [2], [23], [2], [9], [2], [2], [23], [2], [23], [2], [2], [2], [14], [2], [2], [2], [23], [2], [23], [2], [2], [1], [14], [10], [2], [23], [2], [23], [2], [2], [14], [2], [2], [1], [1], [12], [23], [2], [2], [2], [16], [2], [23], [16], [14], [2], [23], [2], [2], [2], [23], [2], [23], [12], [2], [2], [23], [23], [2], [2], [2], [23], [23], [23], [23], [15], [2], [14], [23], [15], [23], [12], [23], [4], [14], [23], [2], [14], [10], [14], [2], [0], [2], [2], [9], [16], [2], [14], [2], [9], [23], [2], [1], [1], [14], [15], [12], [2], [2], [2], [23], [14], [12], [2], [14], [12], [14], [2], [2], [23], [24], [24], [2], [0], [2], [2], [23], [23], [12], [2], [2], [2], [23], [2], [8], [23], [14], [23], [2], [2], [2], [2], [23], [23], [17], [23], [23], [12], [12], [23], [15], [12], [17], [23], [23], [2], [2], [16], [2], [23], [2], [2], [23], [2], [2], [2], [2], [14], [2], [14], [1], [2], [2], [23], [2], [1], [23], [23], [2], [23], [23], [2], [23], [2], [14], [23], [16], [2], [2], [23], [2], [15], [2], [23], [2], [2], [2], [2], [23], [23], [2], [2], [2], [0], [2], [2], [12], [2], [23], [14], [23], [2], [23], [23], [13], [2], [2], [2], [23], [12], [2], [2], [2], [2], [2], [23], [2], [12], [2], [2], [23], [2], [1], [2], [5], [2], [23], [23], [23], [2], [15], [2], [16], [23], [2], [23], [4], [14], [2], [14], [2], [14], [2], [2], [2], [2], [1], [1], [2], [2], [4], [2], [2], [23], [2], [2], [2], [2], [2], [2], [6], [2], [23], [2], [2], [2], [23], [2], [2], [23], [23], [16], [2], [2], [23], [1], [14], [2], [2], [2], [23], [23], [14], [0], [23], [10], [2], [2], [2], [2], [2], [2], [10], [23], [2], [2], [2], [2], [2], [1], [23], [2], [2], [2], [2], [2], [2], [23], [23], [23], [23], [2], [2], [2], [2], [23], [1], [0], [23], [2], [0], [23], [0], [23], [12], [23], [14], [2], [2], [23], [2], [2], [23], [16], [23], [23], [2], [2], [2], [2], [2], [2], [12], [2], [14], [0], [2], [1], [14], [2], [23], [2], [1], [16], [23], [2], [2], [23], [2], [23], [2], [10], [10], [2], [2], [10], [2], [10], [10], [14], [10], [2], [12], [10], [2], [10], [23], [2], [12], [12], [2], [12], [2], [16], [23], [10], [2], [23], [2], [2], [2], [2], [2], [12], [14], [2], [23], [1], [10], [10], [23], [23], [12], [2], [2], [2], [23], [23], [2], [2], [2], [2], [9], [2], [23], [2], [2], [2], [15], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [2], [23], [23], [23], [2], [2], [23], [2], [14], [12], [14], [2], [2], [2], [2], [2], [23], [25], [2], [2], [2], [23], [23], [10], [10], [2], [14], [2], [2], [23], [2], [2], [2], [2], [14], [2], [23], [23], [2], [2], [23], [2], [14], [2], [23], [23], [2], [23], [2], [16], [14], [1], [2], [23], [23], [14], [23], [2], [14], [2], [2], [14], [14], [23], [2], [23], [2], [2], [15], [2], [2], [2], [2], [2], [23], [23], [15], [2], [23], [2], [2], [23], [21], [2], [16], [23], [12], [2], [2], [23], [2], [14], [2], [2], [2], [2], [2], [15], [1], [23], [23], [2], [16], [2], [1], [14], [23], [14], [2], [2], [2], [2], [23], [2], [23], [2], [2], [23], [2], [23], [23], [2], [23], [2], [2], [23], [1], [23], [23], [2], [23], [23], [2], [2], [23], [2], [2], [2], [2], [23], [12], [2], [2], [2], [23], [2], [2], [2], [10], [14], [2], [2], [2], [2], [2], [1], [12], [8], [2], [2], [2], [14], [2], [2], [15], [10], [15], [15], [10], [14], [14], [23], [2], [2], [23], [10], [1], [2], [2], [2], [9], [23], [2], [2], [2], [2], [2], [10], [10], [2], [9], [23], [10], [2], [23], [0], [2], [2], [23], [2], [14], [1], [2], [23], [23], [12], [2], [5], [23], [2], [3], [2], [2], [15], [23], [23], [2], [14], [14], [23], [14], [1], [23], [14], [2], [2], [14], [23], [2], [23], [14], [2], [23], [2], [2], [12], [2], [23], [2], [2], [23], [2], [1], [23], [9], [16], [2], [2], [23], [15], [2], [23], [2], [2], [2], [2], [14], [23], [14], [2], [2], [2], [14], [2], [9], [23], [2], [23], [8], [2], [23], [2], [8], [23], [12], [23], [2], [23], [2], [23], [2], [2], [16], [14], [2], [2], [2], [23], [2], [2], [2], [0], [2], [23], [2], [14], [23], [2], [2], [2], [14], [2], [1], [23], [2], [2], [23], [2], [12], [23], [2], [23], [23], [14], [0], [4], [14], [5], [14], [12], [0], [2], [2], [14], [2], [2], [2], [9], [14], [2], [2], [23], [23], [2], [14], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [12], [14], [23], [23], [2], [14], [23], [2], [2], [2], [2], [2], [23], [12], [2], [2], [23], [2], [0], [5], [2], [2], [14], [23], [2], [23], [24], [2], [23], [23], [2], [2], [2], [21], [2], [23], [2], [12], [2], [14], [23], [12], [2], [2], [2], [2], [10], [2], [2], [2], [2], [2], [23], [12], [2], [0], [23], [23], [2], [15], [2], [2], [2], [2], [15], [2], [4], [2], [2], [0], [16], [2], [2], [14], [14], [2], [14], [2], [2], [2], [23], [2], [19], [12], [2], [2], [23], [2], [2], [14], [2], [2], [2], [2], [16], [15], [23], [2], [2], [21], [12], [12], [23], [1], [23], [4], [23], [2], [2], [2], [2], [2], [12], [14], [2], [12], [12], [2], [23], [23], [2], [2], [2], [15], [2], [15], [23], [2], [2], [2], [23], [2], [2], [12], [2], [2], [12], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [23], [2], [2], [12], [2], [23], [1], [2], [2], [1], [14], [2], [23], [2], [23], [2], [2], [2], [23], [2], [10], [5], [2], [2], [2], [2], [23], [12], [1], [23], [22], [2], [15], [23], [23], [2], [2], [2], [14], [9], [2], [2], [14], [23], [16], [2], [2], [2], [2], [2], [2], [2], [2], [15], [15], [2], [23], [2], [2], [2], [14], [2], [2], [23], [23], [2], [2], [16], [23], [2], [14], [2], [16], [2], [17], [10], [2], [2], [23], [2], [8], [23], [4], [2], [4], [2], [2], [2], [2], [23], [2], [15], [14], [5], [2], [2], [23], [12], [23], [2], [5], [2], [23], [2], [23], [23], [2], [14], [2], [2], [2], [1], [2], [14], [14], [23], [21], [2], [2], [23], [2], [2], [2], [2], [23], [2], [2], [15], [23], [23], [14], [2], [2], [2], [14], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [14], [23], [2], [2], [2], [2], [2], [2], [2], [2], [16], [2], [2], [2], [23], [5], [23], [23], [12], [2], [2], [2], [1], [2], [2], [2], [2], [23], [2], [2], [2], [2], [8], [14], [23], [14], [23], [14], [2], [23], [2], [2], [2], [2], [7], [2], [23], [16], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [2], [12], [2], [2], [2], [2], [14], [2], [2], [2], [14], [2], [23], [14], [2], [9], [14], [2], [14], [15], [2], [2], [2], [23], [23], [2], [2], [14], [15], [23], [2], [23], [2], [12], [2], [12], [2], [2], [12], [2], [2], [2], [14], [23], [2], [2], [16], [14], [10], [5], [14], [23], [23], [16], [23], [23], [14], [2], [7], [2], [2], [2], [2], [2], [14], [15], [23], [2], [2], [2], [12], [2], [14], [8], [23], [2], [2], [2], [2], [23], [2], [12], [2], [2], [2], [10], [23], [23], [12], [2], [23], [23], [2], [23], [2], [2], [2], [9], [2], [23], [2], [23], [23], [2], [16], [23], [23], [2], [23], [23], [2], [2], [2], [2], [2], [2], [23], [15], [23], [12], [12], [2], [2], [2], [2], [2], [2], [2], [14], [4], [2], [2], [2], [23], [2], [4], [14], [2], [22], [2], [2], [2], [5], [2], [22], [2], [2], [15], [23], [23], [2], [2], [2], [10], [2], [2], [2], [2], [2], [23], [2], [23], [14], [23], [2], [23], [9], [2], [15], [2], [2], [2], [2], [2], [12], [2], [15], [2], [1], [2], [2], [23], [2], [14], [14], [2], [2], [2], [2], [2], [15], [2], [14], [12], [2], [2], [23], [2], [2], [2], [16], [23], [14], [2], [2], [23], [23], [2], [23], [2], [2], [23], [2], [2], [23], [23], [12], [23], [2], [14], [14], [2], [2], [14], [23], [2], [14], [2], [23], [23], [14], [2], [2], [23], [10], [2], [2], [2], [23], [2], [23], [2], [12], [23], [2], [23], [23], [2], [23], [2], [2], [7], [23], [2], [2], [2], [12], [2], [2], [23], [2], [2], [14], [2], [23], [23], [2], [2], [2], [1], [23], [15], [2], [2], [23], [2], [9], [2], [2], [2], [23], [2], [2], [2], [2], [2], [15], [2], [23], [2], [23], [2], [2], [8], [2], [14], [23], [23], [2], [1], [2], [2], [2], [2], [23], [10], [2], [2], [2], [2], [14], [2], [2], [23], [2], [21], [23], [2], [2], [12], [14], [23], [2], [9], [23], [2], [2], [14], [2], [2], [2], [23], [2], [2], [16], [2], [14], [2], [12], [2], [14], [2], [2], [2], [23], [2], [2], [2], [16], [2], [23], [12], [2], [2], [2], [2], [23], [2], [14], [2], [23], [2], [10], [2], [10], [2], [2], [14], [23], [23], [23], [4], [2], [14], [23], [10], [2], [10], [10], [12], [2], [2], [2], [2], [23], [2], [23], [2], [23], [23], [2], [2], [23], [2], [4], [2], [2], [2], [3], [2], [23], [23], [23], [2], [15], [2], [12], [2], [2], [14], [2], [2], [2], [10], [10], [2], [10], [2], [10], [2], [2], [10], [2], [2], [10], [23], [2], [10], [2], [2], [16], [10], [2], [23], [10], [2], [10], [2], [2], [10], [23], [10], [2], [2], [2], [23], [2], [10], [23], [23], [2], [10], [2], [2], [2], [23], [2], [23], [2], [2], [1], [14], [2], [21], [2], [2], [14], [14], [23], [2], [2], [2], [12], [2], [14], [10], [14], [16], [2], [4], [21], [2], [15], [10], [2], [15], [23], [2], [14], [23], [2], [2], [14], [23], [12], [12], [12], [23], [2], [6], [2], [9], [14], [14], [2], [2], [23], [2], [1], [4], [2], [16], [23], [0], [2], [23], [21], [0], [14], [23], [10], [2], [23], [2], [2], [2], [2], [2], [17], [2], [2], [2], [3], [2], [14], [2], [12], [10], [2], [2], [2], [10], [2], [23], [2], [2], [2], [2], [10], [2], [2], [2], [16], [2], [2], [15], [15], [2], [2], [4], [2], [2], [16], [14], [10], [16], [23], [2], [10], [10], [2], [12], [23], [14], [2], [10], [2], [10], [10], [10], [2], [10], [23], [10], [10], [2], [10], [10], [10], [2], [2], [2], [23], [2], [23], [10], [23], [23], [23], [23], [2], [23], [23], [2], [23], [14], [2], [2], [23], [23], [23], [23], [2], [4], [14], [14], [2], [2], [16], [2], [14], [2], [2], [8], [2], [10], [2], [14], [10], [10], [10], [10], [2], [12], [10], [10], [10], [12], [10], [2], [19], [2], [23], [2], [10], [10], [10], [10], [2], [14], [10], [2], [10], [10], [23], [23], [2], [10], [10], [10], [10], [10], [10], [2], [10], [10], [23], [10], [10], [2], [2], [10], [10], [10], [10], [10], [10], [2], [2], [10], [10], [8], [2], [2], [2], [0], [10], [23], [2], [2], [2], [4], [2], [2], [2], [16], [10], [23], [12], [10], [2], [10], [2], [2], [2], [2], [2], [2], [2], [14], [2], [10], [2], [10], [10], [23], [2], [17], [23], [10], [10], [23], [10], [10], [10], [10], [15], [10], [10], [23], [10], [2], [2], [2], [2], [23], [2], [23], [2], [2], [2], [23], [2], [15], [2], [2], [2], [2], [15], [15], [16], [2], [4], [2], [15], [14], [2], [2], [2], [2], [2], [2], [14], [2], [4], [2], [2], [2], [2], [2], [23], [2], [14], [2], [2], [1], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [15], [2], [2], [13], [2], [2], [2], [2], [16], [2], [9], [23], [23], [2], [2], [2], [2], [2], [23], [12], [2], [23], [2], [2], [2], [2], [14], [23], [23], [2], [23], [2], [23], [14], [23], [23], [2], [2], [23], [2], [23], [2], [16], [2], [2], [23], [23], [9], [2], [1], [23], [2], [0], [2], [2], [2], [2], [2], [15], [23], [23], [2], [2], [14], [2], [2], [16], [2], [10], [2], [14], [2], [2], [2], [1], [14], [12], [2], [2], [14], [21], [23], [2], [12], [2], [12], [15], [2], [10], [2], [6], [2], [2], [2], [2], [2], [14], [2], [2], [6], [2], [2], [10], [2], [2], [2], [6], [15], [2], [2], [12], [2], [12], [2], [9], [10], [2], [23], [14], [0], [10], [2], [10], [6], [14], [23], [14], [6], [23], [1], [2], [23], [14], [2], [23], [10], [23], [18], [10], [2], [23], [2], [22], [1], [2], [2], [23], [14], [23], [14], [2], [23], [2], [4], [2], [12], [2], [2], [18], [14], [15], [2], [16], [2], [2], [2], [2], [2], [23], [23], [1], [0], [2], [2], [23], [23], [14], [2], [2], [2], [2], [2], [2], [2], [23], [10], [23], [10], [10], [14], [2], [2], [24], [14], [23], [2], [2], [14], [9], [23], [2], [14], [0], [15], [14], [2], [2], [2], [2], [23], [2], [2], [11], [10], [23], [2], [2], [13], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [23], [14], [2], [2], [1], [1], [23], [2], [2], [2], [23], [2], [2], [14], [23], [2], [2], [2], [2], [23], [2], [2], [16], [12], [2], [2], [23], [21], [14], [14], [2], [23], [14], [2], [14], [23], [18], [2], [14], [2], [9], [2], [2], [2], [23], [9], [23], [0], [2], [2], [2], [17], [2], [2], [2], [2], [2], [23], [2], [2], [2], [15], [23], [2], [2], [1], [14], [2], [2], [2], [2], [12], [2], [2], [2], [23], [23], [18], [2], [23], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [16], [2], [23], [2], [23], [2], [2], [2], [12], [14], [9], [2], [23], [24], [23], [23], [2], [14], [10], [23], [15], [23], [15], [13], [1], [2], [2], [6], [14], [8], [9], [2], [23], [10], [10], [10], [10], [2], [10], [2], [23], [23], [2], [23], [12], [2], [1], [2], [23], [2], [2], [2], [23], [10], [2], [23], [23], [2], [23], [2], [12], [12], [23], [6], [23], [12], [1], [12], [23], [2], [23], [12], [23], [23], [2], [23], [2], [23], [2], [14], [16], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [16], [2], [23], [2], [14], [23], [2], [23], [2], [2], [23], [23], [2], [2], [12], [2], [1], [2], [2], [23], [10], [2], [2], [2], [14], [2], [2], [2], [2], [14], [7], [23], [2], [23], [2], [23], [23], [2], [2], [2], [23], [12], [2], [12], [0], [23], [2], [2], [2], [2], [23], [23], [23], [23], [2], [2], [23], [2], [23], [12], [23], [2], [23], [14], [14], [14], [23], [2], [2], [2], [14], [2], [2], [23], [23], [23], [23], [12], [2], [23], [23], [2], [23], [23], [23], [23], [15], [14], [23], [2], [23], [12], [2], [23], [2], [2], [14], [2], [2], [23], [23], [23], [2], [2], [2], [1], [2], [0], [2], [2], [2], [2], [2], [23], [2], [2], [12], [23], [23], [14], [1], [1], [10], [2], [23], [2], [1], [14], [2], [23], [1], [23], [14], [23], [23], [2], [23], [9], [17], [2], [2], [2], [23], [2], [2], [14], [14], [23], [2], [23], [2], [23], [12], [14], [2], [14], [2], [15], [14], [2], [2], [14], [1], [2], [2], [2], [2], [23], [23], [2], [23], [2], [4], [2], [1], [12], [14], [2], [2], [2], [10], [23], [2], [2], [23], [2], [2], [14], [2], [1], [5], [2], [2], [1], [23], [14], [23], [23], [15], [15], [1], [2], [23], [23], [23], [2], [23], [8], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [23], [22], [23], [2], [2], [19], [9], [23], [14], [5], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [10], [2], [10], [2], [2], [2], [2], [2], [2], [1], [10], [2], [10], [23], [2], [2], [2], [2], [23], [2], [19], [2], [2], [23], [23], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [14], [2], [2], [2], [2], [2], [2], [2], [12], [15], [2], [23], [23], [14], [23], [12], [2], [2], [2], [23], [23], [23], [2], [8], [1], [2], [2], [8], [23], [23], [14], [14], [14], [2], [14], [15], [14], [2], [23], [2], [23], [14], [2], [2], [2], [2], [23], [2], [2], [2], [23], [23], [2], [23], [2], [2], [23], [2], [2], [2], [2], [23], [2], [23], [23], [2], [2], [2], [12], [1], [2], [23], [1], [2], [2], [2], [1], [2], [23], [23], [2], [2], [2], [14], [23], [2], [15], [2], [2], [23], [2], [2], [23], [9], [2], [2], [14], [23], [23], [23], [2], [23], [15], [23], [2], [2], [2], [2], [23], [17], [2], [22], [2], [2], [2], [23], [21], [10], [2], [2], [23], [10], [2], [10], [8], [23], [2], [23], [23], [12], [2], [12], [2], [2], [23], [9], [1], [23], [23], [2], [21], [23], [2], [2], [12], [2], [23], [23], [12], [23], [14], [14], [2], [23], [14], [2], [20], [14], [2], [14], [23], [2], [12], [2], [23], [14], [23], [2], [14], [23], [12], [14], [2], [23], [2], [2], [2], [23], [14], [2], [14], [2], [23], [14], [2], [14], [2], [14], [2], [12], [2], [17], [23], [23], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [2], [12], [2], [22], [2], [2], [23], [14], [2], [14], [2], [2], [2], [12], [23], [22], [14], [2], [2], [14], [2], [2], [23], [23], [9], [23], [2], [14], [2], [2], [18], [2], [23], [23], [1], [2], [23], [23], [23], [23], [18], [2], [1], [2], [9], [2], [16], [23], [2], [14], [23], [15], [14], [2], [2], [2], [14], [2], [2], [2], [10], [16], [2], [2], [2], [2], [2], [23], [16], [2], [7], [15], [2], [23], [2], [23], [2], [12], [2], [2], [2], [23], [2], [2], [2], [2], [23], [9], [23], [12], [2], [2], [10], [2], [2], [2], [2], [2], [4], [2], [2], [12], [2], [14], [2], [23], [23], [2], [2], [2], [14], [21], [2], [23], [23], [14], [2], [1], [15], [2], [2], [2], [14], [15], [23], [2], [15], [2], [15], [1], [14], [2], [23], [2], [4], [2], [2], [1], [2], [23], [14], [2], [2], [14], [14], [23], [2], [1], [23], [23], [9], [23], [2], [14], [2], [2], [2], [23], [23], [2], [14], [23], [2], [23], [1], [23], [2], [23], [2], [5], [2], [2], [2], [2], [2], [2], [0], [2], [2], [2], [19], [14], [14], [1], [2], [7], [10], [10], [2], [10], [10], [2], [9], [2], [9], [23], [2], [23], [2], [2], [2], [14], [2], [14], [23], [23], [23], [14], [9], [23], [4], [2], [2], [23], [23], [23], [23], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [25], [23], [23], [23], [14], [23], [23], [2], [2], [16], [15], [2], [15], [15], [23], [2], [15], [2], [2], [14], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [1], [2], [2], [23], [23], [0], [2], [2], [23], [23], [14], [2], [4], [25], [14], [23], [2], [2], [10], [23], [2], [4], [12], [1], [23], [2], [2], [2], [2], [23], [2], [14], [14], [23], [2], [23], [10], [23], [23], [23], [2], [14], [23], [2], [23], [2], [2], [23], [2], [6], [23], [2], [2], [16], [2], [2], [14], [23], [14], [2], [10], [23], [2], [23], [2], [23], [2], [14], [23], [23], [14], [23], [2], [2], [2], [1], [2], [14], [23], [14], [10], [2], [23], [14], [2], [0], [2], [2], [14], [2], [23], [18], [23], [2], [23], [2], [2], [23], [23], [2], [23], [1], [2], [2], [2], [2], [2], [2], [2], [23], [14], [2], [2], [2], [12], [1], [2], [23], [2], [2], [9], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [14], [16], [10], [2], [10], [2], [2], [13], [23], [13], [21], [10], [2], [10], [2], [2], [2], [23], [2], [2], [23], [2], [14], [2], [2], [2], [2], [16], [2], [2], [23], [2], [2], [2], [2], [5], [14], [2], [23], [23], [23], [2], [2], [10], [14], [2], [12], [23], [23], [14], [2], [23], [2], [14], [2], [12], [16], [2], [8], [9], [23], [14], [16], [10], [2], [7], [10], [23], [2], [15], [23], [23], [23], [23], [2], [2], [2], [23], [2], [23], [2], [23], [23], [2], [2], [23], [2], [14], [2], [23], [1], [2], [2], [2], [2], [23], [2], [14], [2], [2], [2], [8], [2], [2], [14], [2], [2], [2], [1], [12], [23], [2], [2], [23], [2], [14], [2], [2], [2], [2], [2], [23], [2], [1], [8], [23], [2], [2], [23], [12], [2], [23], [23], [14], [23], [23], [23], [2], [14], [2], [12], [2], [14], [12], [0], [0], [23], [20], [10], [23], [23], [10], [2], [23], [2], [23], [2], [1], [2], [23], [23], [2], [2], [2], [2], [14], [23], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [2], [5], [2], [23], [23], [2], [23], [2], [14], [14], [2], [23], [1], [10], [2], [2], [10], [10], [2], [10], [23], [2], [2], [2], [2], [2], [14], [2], [1], [10], [2], [15], [10], [2], [2], [4], [2], [2], [23], [15], [2], [4], [2], [25], [23], [2], [23], [23], [14], [2], [15], [2], [2], [23], [2], [15], [2], [2], [2], [15], [10], [2], [15], [15], [23], [2], [15], [2], [2], [2], [16], [18], [2], [23], [2], [2], [2], [15], [12], [2], [2], [15], [15], [23], [2], [23], [2], [12], [2], [12], [15], [23], [23], [14], [2], [10], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [12], [10], [23], [12], [10], [10], [2], [12], [10], [2], [12], [23], [12], [23], [2], [2], [23], [12], [2], [10], [2], [16], [23], [2], [2], [21], [14], [2], [9], [14], [12], [2], [2], [23], [2], [23], [2], [2], [2], [23], [23], [12], [12], [2], [2], [23], [16], [14], [12], [2], [2], [12], [23], [2], [2], [2], [2], [2], [2], [2], [14], [9], [14], [12], [2], [14], [23], [2], [2], [2], [2], [2], [10], [2], [2], [2], [23], [23], [23], [23], [2], [2], [14], [2], [23], [23], [2], [2], [2], [23], [2], [23], [23], [23], [23], [2], [23], [23], [2], [23], [23], [2], [23], [23], [14], [2], [2], [23], [2], [2], [23], [2], [2], [2], [12], [23], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [23], [13], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [23], [2], [2], [2], [15], [12], [10], [2], [23], [23], [2], [2], [14], [23], [23], [14], [23], [2], [12], [2], [12], [2], [23], [23], [2], [2], [1], [2], [2], [14], [14], [2], [4], [12], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [10], [2], [10], [2], [23], [2], [14], [4], [2], [15], [12], [15], [23], [2], [2], [2], [2], [2], [2], [2], [2], [15], [2], [2], [2], [2], [2], [2], [2], [12], [2], [2], [23], [2], [2], [2], [2], [14], [2], [11], [2], [10], [8], [1], [2], [2], [14], [10], [2], [2], [14], [23], [2], [12], [23], [14], [14], [14], [2], [23], [2], [2], [14], [2], [14], [0], [14], [14], [23], [14], [14], [14], [2], [2], [23], [2], [2], [14], [14], [14], [14], [14], [2], [2], [14], [2], [2], [2], [2], [23], [2], [23], [23], [2], [2], [2], [2], [14], [10], [23], [9], [2], [2], [2], [2], [2], [2], [2], [23], [1], [23], [23], [2], [23], [2], [2], [23], [2], [2], [16], [2], [2], [23], [0], [23], [2], [0], [2], [2], [1], [2], [2], [2], [2], [4], [2], [15], [2], [23], [2], [23], [12], [2], [2], [2], [23], [2], [0], [23], [23], [2], [2], [2], [0], [0], [23], [23], [1], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [1], [2], [2], [23], [14], [2], [14], [2], [2], [14], [2], [14], [14], [2], [2], [2], [2], [14], [2], [2], [16], [23], [23], [2], [23], [21], [10], [2], [2], [10], [2], [2], [23], [14], [23], [23], [14], [2], [2], [2], [2], [12], [2], [2], [0], [23], [2], [2], [2], [2], [21], [23], [23], [2], [16], [14], [2], [23], [2], [5], [2], [23], [23], [2], [2], [16], [2], [10], [1], [10], [2], [2], [2], [2], [0], [2], [2], [23], [23], [10], [2], [12], [2], [23], [12], [23], [23], [2], [2], [2], [2], [10], [4], [10], [2], [2], [15], [23], [12], [2], [2], [23], [2], [23], [10], [2], [9], [23], [2], [10], [2], [23], [2], [23], [2], [23], [2], [2], [14], [2], [2], [23], [23], [12], [2], [2], [23], [2], [2], [2], [2], [16], [23], [2], [15], [23], [15], [2], [2], [15], [2], [21], [2], [2], [23], [14], [12], [2], [2], [2], [2], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [23], [23], [12], [12], [23], [2], [14], [2], [14], [2], [2], [2], [2], [14], [23], [1], [16], [23], [23], [2], [23], [14], [2], [5], [2], [2], [23], [2], [23], [14], [5], [2], [14], [2], [2], [2], [2], [2], [16], [10], [12], [2], [12], [2], [2], [23], [2], [2], [2], [23], [2], [2], [23], [23], [23], [23], [14], [23], [2], [2], [2], [23], [23], [14], [2], [23], [12], [10], [2], [2], [2], [4], [21], [10], [23], [23], [23], [2], [2], [12], [2], [2], [2], [23], [2], [2], [2], [10], [10], [10], [23], [10], [10], [12], [23], [10], [2], [2], [12], [2], [12], [0], [22], [14], [2], [12], [23], [23], [2], [2], [2], [2], [14], [2], [2], [14], [2], [6], [2], [2], [14], [14], [2], [2], [2], [0], [23], [2], [23], [23], [2], [14], [2], [2], [15], [2], [15], [2], [2], [2], [15], [23], [15], [9], [15], [23], [14], [2], [14], [8], [0], [23], [2], [23], [2], [14], [8], [2], [2], [8], [8], [7], [14], [23], [9], [2], [23], [23], [14], [1], [2], [5], [2], [2], [18], [14], [18], [14], [12], [1], [2], [23], [10], [2], [2], [2], [15], [14], [2], [5], [2], [2], [2], [2], [2], [2], [2], [15], [2], [12], [2], [14], [23], [23], [14], [16], [23], [23], [23], [23], [14], [2], [23], [2], [16], [2], [12], [23], [0], [2], [2], [2], [2], [14], [2], [16], [14], [23], [2], [8], [14], [10], [2], [14], [2], [23], [23], [2], [2], [14], [2], [23], [14], [23], [2], [2], [2], [2], [2], [2], [2], [14], [23], [23], [23], [2], [2], [2], [10], [2], [2], [10], [2], [14], [2], [23], [10], [2], [23], [8], [15], [14], [14], [2], [12], [10], [14], [2], [14], [2], [14], [23], [2], [14], [2], [2], [14], [23], [2], [2], [2], [0], [14], [23], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [17], [18], [2], [15], [2], [2], [2], [23], [2], [2], [14], [1], [15], [2], [2], [2], [2], [23], [23], [2], [14], [2], [2], [14], [23], [16], [2], [14], [2], [2], [14], [2], [2], [2], [14], [16], [2], [2], [2], [14], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [4], [2], [14], [12], [2], [2], [14], [2], [23], [2], [2], [12], [2], [23], [2], [23], [14], [2], [10], [10], [2], [2], [2], [2], [2], [2], [23], [14], [23], [10], [2], [2], [23], [2], [2], [0], [2], [16], [2], [9], [9], [2], [16], [15], [2], [23], [2], [2], [15], [2], [2], [12], [16], [14], [2], [2], [2], [2], [15], [2], [12], [2], [23], [2], [4], [4], [23], [2], [2], [1], [2], [2], [23], [2], [2], [2], [2], [14], [2], [23], [2], [2], [2], [2], [0], [16], [23], [2], [23], [1], [23], [2], [9], [23], [2], [2], [8], [10], [23], [2], [2], [23], [21], [10], [2], [2], [2], [15], [23], [10], [2], [1], [2], [2], [2], [14], [2], [23], [2], [10], [0], [23], [2], [2], [2], [23], [14], [2], [2], [2], [14], [2], [2], [2], [2], [14], [2], [2], [2], [23], [7], [14], [5], [23], [14], [2], [12], [2], [2], [2], [2], [10], [2], [1], [2], [23], [2], [2], [2], [2], [23], [2], [2], [2], [2], [0], [2], [12], [25], [5], [2], [10], [2], [14], [8], [2], [2], [23], [21], [2], [2], [2], [2], [2], [14], [2], [2], [5], [2], [23], [16], [5], [2], [14], [1], [2], [2], [2], [2], [14], [2], [2], [2], [2], [10], [23], [0], [14], [12], [14], [2], [23], [2], [14], [9], [2], [2], [21], [2], [2], [14], [23], [2], [2], [2], [2], [14], [2], [2], [14], [2], [23], [14], [23], [1], [2], [2], [2], [7], [2], [23], [23], [23], [14], [15], [2], [14], [14], [2], [23], [12], [23], [23], [2], [2], [2], [2], [14], [2], [23], [23], [2], [2], [23], [2], [14], [10], [14], [2], [2], [2], [23], [14], [2], [2], [16], [23], [2], [23], [0], [2], [2], [2], [2], [0], [2], [2], [23], [5], [23], [2], [14], [2], [1], [2], [23], [2], [23], [23], [10], [2], [2], [16], [8], [2], [2], [2], [14], [23], [2], [2], [2], [9], [23], [2], [23], [2], [14], [14], [23], [2], [2], [2], [2], [12], [16], [12], [16], [14], [14], [14], [2], [12], [2], [4], [23], [23], [2], [2], [1], [2], [1], [2], [14], [23], [14], [23], [2], [2], [0], [14], [0], [12], [0], [23], [2], [2], [0], [6], [23], [2], [23], [0], [2], [16], [14], [14], [0], [0], [16], [14], [2], [14], [14], [2], [2], [2], [16], [2], [2], [23], [2], [2], [16], [23], [23], [2], [8], [2], [2], [14], [2], [6], [2], [2], [14], [2], [14], [12], [2], [2], [23], [23], [14], [2], [2], [2], [2], [2], [1], [10], [23], [23], [2], [2], [14], [14], [0], [2], [2], [16], [2], [1], [23], [10], [23], [2], [23], [14], [23], [14], [12], [24], [2], [23], [2], [3], [5], [2], [12], [2], [2], [2], [2], [2], [2], [0], [7], [12], [14], [2], [14], [7], [8], [23], [2], [2], [14], [23], [1], [2], [23], [14], [2], [2], [2], [14], [2], [2], [23], [14], [2], [23], [2], [2], [23], [2], [14], [2], [16], [23], [2], [2], [2], [2], [23], [2], [23], [2], [14], [9], [14], [14], [12], [14], [23], [14], [14], [14], [2], [2], [12], [1], [16], [14], [0], [23], [2], [2], [23], [1], [2], [14], [14], [23], [2], [2], [0], [2], [23], [2], [2], [6], [12], [2], [2], [2], [2], [2], [23], [14], [14], [2], [14], [5], [23], [23], [14], [2], [23], [23], [6], [23], [2], [12], [2], [2], [23], [12], [2], [2], [4], [14], [23], [14], [23], [2], [14], [14], [23], [12], [14], [2], [10], [2], [2], [23], [23], [2], [2], [18], [23], [23], [2], [2], [14], [14], [2], [12], [1], [2], [2], [23], [2], [2], [2], [23], [23], [2], [2], [2], [2], [2], [12], [2], [2], [16], [2], [14], [21], [14], [23], [1], [2], [14], [6], [21], [23], [14], [14], [5], [12], [23], [2], [2], [23], [23], [14], [2], [1], [2], [23], [23], [23], [14], [16], [2], [2], [21], [23], [2], [23], [23], [14], [2], [2], [2], [2], [2], [10], [1], [5], [14], [23], [2], [2], [23], [10], [10], [12], [2], [14], [2], [16], [8], [2], [2], [2], [2], [12], [2], [2], [12], [10], [12], [2], [23], [2], [14], [17], [2], [2], [2], [1], [10], [1], [2], [2], [12], [2], [2], [2], [2], [23], [23], [2], [2], [2], [2], [2], [2], [10], [2], [2], [23], [2], [2], [14], [2], [23], [23], [23], [2], [8], [23], [2], [2], [8], [5], [2], [17], [23], [8], [23], [2], [2], [23], [14], [2], [2], [14], [2], [12], [16], [14], [16], [0], [2], [2], [23], [2], [15], [2], [2], [14], [2], [23], [2], [1], [23], [0], [14], [17], [2], [23], [23], [2], [2], [2], [2], [23], [14], [2], [0], [12], [12], [23], [2], [12], [2], [2], [14], [2], [23], [23], [16], [23], [14], [23], [14], [16], [0], [23], [23], [23], [14], [2], [15], [2], [15], [2], [23], [2], [14], [2], [14], [14], [2], [2], [23], [14], [14], [1], [2], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [2], [14], [2], [23], [2], [23], [12], [12], [0], [2], [2], [12], [10], [12], [10], [10], [2], [2], [16], [15], [14], [12], [23], [2], [2], [10], [23], [2], [23], [15], [10], [23], [23], [2], [11], [2], [12], [2], [23], [2], [23], [2], [23], [2], [9], [2], [0], [23], [0], [2], [2], [2], [14], [2], [23], [14], [10], [10], [10], [23], [14], [14], [2], [2], [8], [23], [12], [2], [2], [2], [14], [13], [14], [14], [2], [14], [2], [2], [2], [23], [12], [14], [9], [2], [2], [14], [14], [2], [23], [23], [4], [2], [23], [14], [23], [2], [12], [2], [23], [2], [12], [2], [1], [23], [23], [2], [2], [2], [2], [2], [12], [2], [15], [14], [2], [12], [0], [2], [2], [9], [2], [2], [6], [23], [2], [15], [14], [16], [10], [23], [15], [1], [14], [15], [23], [12], [12], [2], [16], [2], [12], [0], [23], [23], [2], [2], [2], [23], [10], [23], [2], [2], [8], [2], [12], [2], [23], [2], [2], [2], [16], [2], [2], [5], [2], [2], [15], [16], [2], [2], [10], [5], [23], [2], [2], [10], [23], [2], [2], [2], [14], [2], [2], [12], [23], [9], [2], [16], [14], [14], [2], [15], [2], [2], [1], [2], [2], [0], [2], [2], [14], [8], [2], [23], [2], [2], [2], [2], [23], [2], [2], [7], [23], [9], [14], [14], [23], [14], [9], [21], [0], [2], [2], [2], [2], [2], [14], [2], [5], [16], [2], [2], [2], [23], [2], [2], [23], [23], [2], [2], [2], [23], [0], [2], [5], [2], [23], [12], [23], [23], [14], [2], [23], [2], [14], [25], [12], [2], [2], [23], [23], [23], [23], [23], [14], [8], [23], [2], [23], [2], [8], [0], [23], [2], [23], [16], [2], [16], [5], [2], [2], [0], [2], [2], [2], [10], [23], [2], [2], [2], [2], [2], [2], [16], [2], [2], [8], [1], [1], [2], [2], [2], [14], [2], [12], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [14], [2], [16], [11], [2], [2], [23], [2], [2], [2], [12], [23], [1], [15], [9], [2], [14], [23], [2], [14], [14], [14], [16], [2], [2], [12], [2], [14], [2], [12], [14], [2], [2], [23], [23], [23], [23], [2], [23], [14], [2], [23], [16], [10], [23], [23], [2], [14], [2], [23], [10], [2], [23], [2], [12], [2], [2], [14], [23], [2], [23], [2], [23], [2], [23], [5], [2], [14], [1], [14], [14], [12], [2], [12], [2], [14], [2], [2], [2], [14], [2], [2], [2], [12], [14], [2], [14], [2], [23], [23], [8], [23], [14], [23], [14], [2], [21], [14], [14], [2], [12], [5], [15], [2], [23], [2], [2], [2], [12], [2], [2], [2], [23], [2], [2], [2], [2], [2], [1], [2], [2], [23], [2], [2], [2], [23], [2], [2], [14], [2], [2], [14], [14], [2], [2], [15], [2], [2], [16], [10], [2], [2], [2], [2], [14], [2], [2], [0], [2], [2], [12], [23], [2], [23], [2], [12], [14], [2], [23], [12], [23], [14], [12], [1], [23], [1], [2], [1], [23], [23], [2], [12], [20], [23], [2], [23], [2], [2], [2], [15], [2], [2], [2], [2], [0], [2], [2], [14], [2], [2], [2], [23], [23], [2], [23], [2], [2], [2], [23], [12], [12], [2], [2], [1], [2], [12], [2], [2], [23], [2], [2], [2], [1], [2], [23], [23], [2], [2], [2], [9], [2], [2], [14], [2], [2], [2], [2], [2], [2], [10], [2], [2], [2], [2], [2], [2], [2], [12], [2], [2], [2], [16], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [2], [23], [2], [2], [0], [2], [23], [0], [2], [14], [2], [2], [2], [2], [10], [0], [10], [23], [2], [2], [12], [2], [12], [14], [2], [23], [2], [23], [14], [2], [2], [2], [21], [5], [2], [23], [23], [2], [2], [23], [2], [2], [2], [14], [10], [2], [2], [15], [15], [14], [23], [2], [16], [12], [5], [2], [23], [23], [4], [21], [1], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [10], [23], [2], [2], [2], [23], [2], [0], [14], [2], [23], [2], [9], [23], [14], [2], [2], [2], [2], [2], [23], [0], [12], [2], [2], [2], [14], [1], [2], [5], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [16], [14], [5], [2], [14], [14], [2], [23], [23], [2], [12], [2], [2], [2], [2], [2], [2], [1], [12], [12], [2], [2], [23], [2], [2], [2], [23], [23], [12], [9], [2], [5], [2], [2], [16], [14], [2], [12], [2], [12], [1], [23], [2], [18], [23], [2], [14], [2], [2], [16], [2], [2], [2], [23], [23], [2], [1], [16], [2], [2], [16], [14], [2], [2], [2], [2], [15], [23], [23], [2], [2], [12], [2], [14], [2], [2], [14], [2], [2], [1], [2], [1], [0], [23], [23], [2], [2], [12], [23], [2], [12], [23], [14], [23], [1], [2], [2], [23], [2], [23], [2], [23], [23], [2], [14], [23], [2], [23], [14], [2], [2], [0], [2], [2], [1], [23], [2], [2], [2], [14], [2], [14], [14], [23], [2], [1], [2], [2], [2], [2], [23], [12], [2], [2], [14], [14], [23], [23], [23], [2], [2], [2], [23], [2], [10], [2], [2], [2], [2], [2], [10], [10], [4], [2], [9], [10], [23], [9], [2], [2], [10], [2], [23], [23], [2], [14], [12], [15], [1], [2], [2], [2], [2], [2], [2], [23], [23], [16], [14], [1], [8], [12], [1], [1], [14], [2], [14], [22], [14], [2], [25], [2], [2], [2], [1], [12], [2], [2], [2], [12], [14], [23], [2], [2], [2], [12], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [10], [2], [14], [2], [21], [14], [2], [23], [2], [2], [2], [12], [2], [23], [2], [2], [14], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [23], [8], [23], [2], [2], [2], [23], [14], [23], [2], [23], [23], [23], [2], [2], [2], [23], [2], [2], [23], [23], [2], [2], [12], [2], [2], [2], [2], [2], [2], [23], [2], [14], [2], [2], [23], [23], [2], [2], [2], [2], [2], [10], [2], [12], [14], [2], [2], [15], [23], [4], [2], [23], [23], [2], [2], [23], [23], [2], [2], [8], [2], [12], [12], [2], [2], [23], [23], [23], [2], [2], [2], [14], [2], [2], [14], [14], [2], [2], [0], [2], [2], [2], [2], [2], [10], [0], [2], [2], [2], [0], [0], [2], [0], [0], [0], [15], [2], [2], [0], [23], [0], [2], [14], [2], [2], [0], [2], [0], [0], [23], [8], [0], [2], [9], [2], [12], [23], [2], [1], [23], [2], [14], [2], [4], [23], [2], [14], [2], [0], [2], [23], [2], [0], [23], [0], [2], [7], [9], [2], [23], [9], [2], [23], [2], [12], [2], [2], [2], [2], [1], [2], [23], [23], [14], [2], [23], [10], [2], [2], [10], [2], [2], [2], [2], [23], [23], [23], [23], [2], [12], [2], [2], [2], [2], [2], [2], [12], [2], [23], [14], [12], [2], [2], [2], [14], [2], [2], [2], [0], [12], [2], [2], [23], [2], [12], [2], [14], [14], [2], [23], [2], [23], [23], [2], [14], [2], [2], [23], [2], [2], [23], [1], [2], [23], [2], [2], [2], [12], [16], [2], [14], [2], [2], [1], [23], [2], [23], [23], [2], [23], [23], [23], [2], [23], [2], [2], [23], [5], [14], [12], [23], [2], [2], [23], [2], [2], [12], [2], [17], [2], [21], [2], [23], [12], [2], [2], [2], [14], [2], [2], [9], [14], [14], [2], [2], [2], [2], [2], [2], [14], [2], [2], [14], [2], [2], [16], [2], [2], [2], [15], [2], [2], [2], [2], [14], [14], [14], [23], [2], [23], [2], [23], [12], [2], [23], [2], [23], [23], [23], [1], [23], [23], [23], [16], [2], [2], [23], [16], [2], [2], [2], [2], [2], [16], [2], [23], [23], [2], [2], [0], [2], [14], [16], [1], [2], [2], [23], [2], [23], [2], [12], [23], [2], [2], [2], [10], [23], [16], [23], [2], [2], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [23], [23], [1], [2], [1], [23], [23], [2], [2], [2], [23], [2], [14], [2], [23], [2], [2], [14], [10], [24], [14], [2], [2], [2], [23], [2], [2], [23], [2], [2], [1], [23], [10], [12], [14], [23], [2], [10], [2], [2], [2], [10], [2], [23], [14], [2], [23], [14], [2], [2], [23], [23], [23], [0], [14], [23], [2], [2], [12], [23], [2], [2], [2], [23], [2], [1], [2], [23], [2], [2], [2], [5], [23], [2], [2], [23], [23], [13], [23], [23], [23], [15], [2], [2], [2], [8], [2], [12], [14], [2], [2], [2], [6], [2], [2], [2], [2], [23], [2], [23], [23], [2], [25], [23], [2], [23], [2], [1], [2], [0], [23], [14], [2], [2], [12], [2], [23], [2], [2], [2], [23], [2], [1], [16], [2], [2], [2], [14], [2], [23], [14], [5], [10], [2], [21], [2], [1], [14], [14], [2], [2], [16], [23], [2], [23], [23], [23], [23], [2], [2], [2], [23], [2], [10], [2], [14], [14], [23], [10], [2], [2], [2], [14], [16], [23], [2], [2], [12], [23], [0], [2], [2], [2], [1], [14], [2], [16], [14], [5], [6], [14], [2], [23], [2], [2], [9], [23], [2], [1], [2], [2], [2], [21], [23], [23], [2], [2], [2], [14], [0], [2], [12], [2], [1], [2], [0], [2], [7], [2], [2], [2], [2], [23], [23], [4], [14], [14], [2], [23], [12], [14], [14], [14], [14], [12], [23], [2], [23], [10], [23], [14], [2], [14], [2], [14], [14], [2], [2], [2], [14], [2], [2], [2], [10], [2], [14], [23], [2], [0], [14], [1], [2], [23], [2], [14], [2], [2], [14], [23], [23], [23], [15], [2], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [2], [2], [8], [23], [2], [5], [2], [16], [23], [5], [2], [23], [2], [2], [23], [2], [23], [1], [21], [2], [2], [2], [23], [2], [23], [23], [2], [9], [12], [12], [14], [2], [14], [2], [23], [23], [2], [2], [2], [23], [2], [2], [23], [14], [2], [2], [14], [2], [23], [2], [2], [2], [2], [23], [23], [2], [23], [23], [2], [14], [2], [23], [2], [23], [2], [2], [2], [2], [14], [2], [23], [2], [16], [2], [4], [2], [14], [23], [2], [2], [2], [2], [23], [14], [14], [23], [23], [2], [2], [14], [23], [2], [23], [2], [2], [19], [2], [23], [2], [1], [23], [2], [14], [23], [23], [23], [1], [1], [2], [2], [2], [2], [8], [2], [2], [23], [2], [2], [22], [2], [21], [2], [2], [2], [14], [15], [0], [0], [2], [0], [0], [23], [2], [0], [2], [2], [2], [0], [2], [12], [0], [23], [0], [0], [2], [14], [0], [2], [2], [14], [2], [23], [12], [14], [0], [2], [23], [2], [2], [0], [0], [2], [0], [0], [2], [15], [2], [2], [2], [2], [2], [2], [14], [14], [0], [2], [15], [5], [23], [2], [2], [15], [2], [2], [10], [2], [23], [2], [23], [23], [2], [12], [2], [2], [12], [16], [2], [2], [2], [2], [2], [2], [2], [15], [2], [2], [23], [2], [24], [2], [1], [23], [2], [23], [2], [23], [16], [2], [23], [23], [16], [2], [23], [14], [23], [2], [2], [2], [2], [16], [23], [2], [2], [2], [2], [23], [23], [2], [12], [2], [23], [10], [12], [2], [2], [2], [0], [1], [2], [12], [2], [2], [15], [2], [2], [14], [2], [2], [2], [14], [2], [21], [23], [0], [1], [12], [23], [23], [2], [2], [23], [23], [2], [14], [2], [1], [23], [14], [2], [10], [2], [10], [2], [1], [2], [23], [2], [10], [2], [2], [10], [23], [2], [2], [2], [23], [14], [4], [16], [2], [2], [14], [2], [14], [2], [2], [2], [2], [9], [12], [23], [23], [2], [2], [14], [1], [17], [14], [14], [23], [2], [2], [2], [17], [2], [12], [23], [12], [23], [10], [12], [14], [2], [23], [12], [2], [14], [2], [1], [2], [2], [2], [5], [23], [14], [2], [16], [8], [14], [2], [2], [2], [12], [10], [23], [10], [2], [2], [2], [2], [14], [2], [23], [2], [1], [2], [2], [0], [2], [2], [23], [14], [2], [23], [23], [15], [2], [2], [2], [14], [17], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [0], [1], [14], [0], [2], [0], [0], [23], [2], [0], [0], [2], [0], [15], [2], [16], [2], [14], [12], [2], [0], [2], [2], [2], [10], [4], [2], [2], [2], [2], [0], [2], [2], [2], [2], [0], [2], [0], [2], [14], [23], [0], [2], [2], [2], [2], [23], [2], [14], [23], [23], [2], [2], [2], [2], [2], [23], [1], [2], [2], [10], [2], [2], [2], [10], [10], [23], [10], [10], [23], [2], [2], [2], [10], [14], [14], [12], [2], [2], [2], [14], [2], [23], [12], [2], [2], [2], [14], [2], [2], [14], [12], [23], [23], [2], [14], [2], [2], [2], [23], [2], [2], [2], [23], [2], [2], [2], [2], [12], [2], [23], [25], [2], [2], [2], [2], [2], [2], [10], [2], [10], [2], [2], [10], [2], [23], [2], [23], [2], [10], [2], [23], [12], [2], [2], [14], [2], [12], [2], [6], [12], [14], [12], [23], [2], [2], [23], [23], [23], [23], [23], [2], [2], [2], [2], [15], [2], [2], [23], [2], [0], [14], [2], [16], [2], [23], [2], [2], [2], [2], [2], [8], [2], [2], [14], [2], [5], [2], [2], [2], [23], [2], [25], [14], [23], [1], [14], [14], [2], [12], [2], [2], [14], [2], [23], [10], [10], [10], [10], [2], [10], [10], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [12], [2], [23], [14], [14], [2], [2], [23], [2], [2], [2], [12], [2], [2], [2], [23], [1], [14], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [23], [2], [16], [2], [2], [23], [2], [2], [14], [17], [2], [23], [2], [2], [2], [23], [2], [23], [2], [23], [14], [2], [4], [2], [12], [14], [2], [23], [12], [2], [23], [2], [1], [2], [8], [1], [2], [8], [23], [2], [2], [2], [12], [2], [14], [1], [2], [2], [2], [2], [23], [2], [5], [23], [2], [23], [2], [2], [0], [2], [2], [23], [0], [2], [2], [2], [2], [2], [2], [2], [14], [2], [23], [2], [23], [1], [23], [1], [2], [2], [8], [12], [2], [2], [2], [12], [2], [2], [2], [1], [2], [2], [2], [23], [2], [23], [2], [10], [12], [2], [2], [2], [15], [14], [2], [23], [2], [6], [23], [14], [2], [2], [12], [23], [2], [14], [2], [23], [2], [9], [23], [6], [23], [9], [21], [6], [14], [2], [23], [2], [12], [2], [23], [2], [23], [2], [23], [2], [1], [1], [14], [14], [23], [5], [0], [2], [2], [2], [2], [23], [2], [14], [2], [23], [23], [2], [2], [2], [2], [14], [2], [2], [23], [2], [14], [14], [2], [8], [2], [2], [2], [8], [23], [16], [2], [6], [1], [23], [12], [23], [2], [2], [14], [2], [16], [2], [2], [21], [16], [23], [2], [12], [16], [2], [14], [2], [2], [9], [2], [23], [23], [2], [2], [8], [23], [23], [2], [10], [2], [2], [23], [2], [2], [2], [23], [14], [23], [10], [2], [2], [23], [12], [16], [23], [2], [2], [14], [0], [23], [8], [23], [14], [2], [2], [2], [14], [14], [15], [14], [2], [2], [2], [2], [24], [9], [2], [14], [9], [14], [4], [12], [12], [2], [12], [23], [14], [23], [2], [2], [2], [2], [23], [23], [2], [14], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [10], [16], [2], [12], [2], [21], [23], [2], [10], [10], [10], [2], [2], [2], [10], [2], [10], [2], [2], [2], [1], [12], [2], [14], [2], [23], [14], [16], [9], [2], [2], [2], [2], [2], [2], [10], [2], [2], [14], [2], [2], [15], [14], [23], [2], [23], [2], [2], [2], [2], [2], [2], [23], [14], [16], [5], [14], [17], [2], [8], [16], [2], [2], [16], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [12], [12], [10], [5], [12], [10], [2], [10], [1], [10], [10], [10], [2], [10], [10], [12], [14], [14], [10], [2], [14], [14], [10], [14], [10], [12], [23], [2], [14], [2], [2], [2], [2], [2], [10], [2], [23], [23], [23], [23], [16], [1], [23], [23], [12], [1], [14], [2], [2], [4], [12], [10], [2], [2], [2], [2], [12], [2], [15], [1], [2], [2], [2], [15], [1], [2], [2], [12], [2], [2], [2], [2], [23], [2], [2], [5], [8], [2], [2], [23], [2], [23], [8], [2], [23], [2], [2], [2], [23], [2], [2], [12], [8], [2], [2], [23], [23], [2], [2], [2], [1], [2], [14], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [2], [14], [14], [23], [23], [2], [23], [23], [2], [2], [2], [23], [23], [23], [2], [2], [2], [12], [23], [14], [2], [14], [2], [9], [23], [2], [2], [14], [14], [2], [10], [2], [23], [1], [2], [23], [2], [2], [23], [23], [2], [2], [2], [14], [23], [2], [14], [19], [12], [2], [21], [7], [14], [2], [23], [23], [2], [23], [2], [2], [12], [2], [23], [23], [23], [16], [23], [23], [2], [2], [23], [1], [23], [12], [2], [2], [2], [23], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [8], [14], [2], [12], [2], [2], [2], [2], [14], [14], [2], [2], [2], [2], [12], [2], [2], [14], [2], [12], [2], [2], [23], [2], [14], [23], [23], [14], [14], [2], [2], [2], [12], [2], [2], [2], [2], [2], [12], [2], [23], [2], [5], [23], [2], [2], [2], [23], [5], [14], [2], [2], [2], [14], [2], [2], [23], [2], [23], [9], [12], [23], [2], [2], [2], [2], [7], [14], [14], [16], [2], [8], [2], [8], [2], [2], [10], [2], [8], [2], [2], [2], [14], [16], [23], [10], [2], [2], [1], [2], [2], [2], [2], [23], [12], [20], [16], [2], [2], [2], [16], [2], [1], [1], [5], [12], [2], [2], [17], [2], [2], [2], [8], [23], [23], [2], [2], [23], [2], [12], [23], [2], [2], [2], [2], [1], [14], [2], [2], [2], [2], [2], [14], [23], [2], [2], [23], [15], [14], [2], [2], [2], [12], [23], [5], [2], [12], [2], [2], [16], [2], [2], [2], [2], [14], [2], [2], [12], [2], [14], [16], [2], [2], [2], [2], [2], [12], [10], [12], [23], [2], [2], [23], [1], [2], [2], [2], [2], [2], [2], [2], [10], [10], [10], [2], [10], [10], [10], [10], [2], [10], [23], [2], [2], [2], [14], [10], [10], [9], [12], [2], [14], [5], [10], [10], [14], [2], [5], [10], [10], [2], [2], [2], [14], [2], [2], [2], [2], [6], [2], [2], [2], [1], [2], [23], [2], [2], [2], [5], [14], [2], [1], [2], [2], [14], [1], [8], [2], [14], [2], [2], [14], [2], [1], [2], [2], [2], [2], [2], [15], [2], [23], [14], [16], [14], [15], [12], [23], [2], [15], [23], [2], [12], [16], [2], [1], [2], [12], [2], [14], [2], [2], [23], [12], [2], [12], [1], [8], [2], [2], [14], [2], [2], [12], [16], [14], [1], [14], [14], [2], [2], [12], [23], [15], [23], [23], [10], [12], [23], [2], [2], [2], [2], [2], [14], [23], [14], [14], [14], [23], [23], [2], [2], [2], [2], [2], [2], [2], [5], [2], [2], [10], [19], [16], [14], [2], [2], [2], [12], [2], [2], [14], [10], [23], [2], [14], [14], [1], [12], [2], [2], [14], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [12], [2], [12], [2], [2], [23], [12], [22], [2], [2], [10], [2], [1], [2], [2], [10], [16], [16], [14], [23], [23], [15], [16], [23], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [15], [16], [2], [15], [10], [23], [2], [23], [14], [2], [23], [16], [7], [23], [12], [2], [9], [14], [14], [2], [10], [9], [9], [23], [2], [23], [16], [2], [10], [23], [16], [23], [23], [23], [10], [2], [10], [23], [2], [2], [12], [2], [2], [16], [14], [2], [12], [2], [12], [23], [14], [12], [2], [14], [14], [2], [2], [23], [2], [12], [10], [2], [10], [2], [2], [14], [2], [2], [23], [2], [23], [2], [1], [2], [12], [12], [12], [23], [23], [23], [10], [12], [10], [23], [10], [2], [12], [9], [23], [2], [16], [14], [1], [2], [2], [23], [23], [6], [2], [12], [2], [2], [2], [2], [12], [12], [2], [14], [12], [2], [2], [2], [2], [6], [2], [14], [2], [2], [14], [6], [2], [12], [12], [12], [2], [2], [12], [23], [2], [2], [12], [12], [12], [2], [2], [12], [2], [12], [2], [12], [12], [1], [2], [2], [2], [16], [23], [12], [16], [16], [14], [2], [2], [14], [2], [14], [12], [2], [2], [4], [16], [2], [23], [10], [2], [23], [2], [14], [2], [16], [2], [3], [2], [23], [2], [23], [2], [23], [15], [23], [9], [23], [14], [12], [2], [23], [9], [12], [4], [12], [16], [10], [10], [2], [10], [23], [2], [23], [9], [23], [23], [9], [2], [23], [23], [1], [23], [14], [4], [10], [23], [23], [2], [23], [12], [2], [16], [14], [14], [2], [23], [23], [23], [10], [2], [2], [2], [2], [2], [9], [12], [2], [1], [2], [14], [12], [2], [2], [23], [14], [2], [2], [14], [23], [16], [2], [2], [10], [23], [2], [23], [2], [23], [23], [23], [2], [23], [23], [4], [2], [23], [2], [23], [16], [15], [1], [2], [19], [2], [2], [2], [2], [2], [2], [23], [2], [23], [23], [2], [23], [2], [23], [2], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [2], [10], [2], [23], [9], [23], [1], [23], [23], [2], [12], [23], [12], [12], [2], [12], [2], [23], [2], [9], [2], [10], [10], [10], [10], [10], [2], [10], [10], [10], [10], [10], [1], [10], [10], [14], [2], [16], [1], [23], [14], [10], [23], [23], [10], [23], [14], [23], [12], [12], [14], [2], [4], [2], [2], [16], [2], [1], [2], [10], [2], [2], [2], [1], [10], [2], [10], [2], [2], [16], [2], [2], [15], [2], [23], [2], [2], [2], [23], [23], [2], [23], [9], [23], [23], [4], [2], [0], [2], [23], [8], [23], [2], [2], [17], [14], [2], [1], [23], [14], [2], [23], [23], [23], [6], [14], [2], [6], [6], [10], [10], [2], [10], [2], [2], [2], [2], [2], [2], [2], [10], [2], [2], [2], [12], [23], [1], [1], [15], [2], [23], [14], [2], [23], [12], [2], [12], [12], [16], [10], [6], [2], [16], [23], [2], [23], [2], [23], [2], [7], [2], [2], [2], [14], [23], [23], [23], [16], [23], [23], [16], [2], [2], [1], [23], [2], [2], [2], [0], [23], [2], [12], [2], [23], [2], [2], [2], [12], [2], [2], [2], [23], [23], [23], [2], [23], [23], [23], [23], [23], [2], [2], [23], [2], [2], [2], [23], [23], [23], [23], [2], [2], [2], [23], [14], [8], [1], [2], [10], [10], [10], [2], [10], [10], [10], [23], [10], [10], [10], [10], [2], [2], [2], [2], [1], [2], [2], [2], [23], [2], [16], [2], [2], [2], [2], [2], [23], [2], [10], [2], [2], [2], [2], [2], [16], [23], [2], [2], [2], [23], [16], [2], [2], [10], [23], [2], [23], [2], [23], [23], [2], [16], [10], [2], [2], [2], [2], [2], [23], [10], [23], [23], [15], [23], [23], [16], [2], [2], [23], [23], [2], [14], [2], [2], [2], [14], [23], [23], [10], [23], [2], [14], [1], [23], [2], [2], [23], [1], [1], [12], [2], [2], [15], [23], [2], [23], [2], [23], [2], [23], [23], [2], [2], [23], [2], [23], [2], [2], [16], [14], [16], [1], [23], [1], [2], [2], [12], [2], [7], [10], [2], [10], [2], [10], [10], [10], [2], [10], [23], [2], [2], [2], [2], [2], [23], [1], [23], [23], [2], [2], [2], [23], [2], [16], [2], [2], [23], [6], [23], [2], [12], [2], [23], [2], [12], [23], [2], [23], [2], [23], [2], [8], [23], [23], [2], [8], [2], [14], [2], [12], [23], [10], [23], [8], [2], [6], [2], [23], [9], [14], [25], [10], [10], [23], [23], [14], [23], [16], [23], [2], [2], [2], [12], [23], [2], [2], [10], [23], [10], [10], [23], [2], [2], [5], [2], [2], [23], [10], [2], [10], [10], [10], [10], [2], [2], [23], [14], [2], [2], [5], [2], [16], [23], [23], [2], [16], [15], [14], [2], [2], [12], [2], [12], [23], [2], [12], [6], [6], [2], [12], [12], [2], [12], [23], [23], [16], [23], [23], [12], [12], [14], [14], [23], [23], [2], [23], [16], [2], [2], [12], [23], [23], [23], [17], [23], [16], [23], [2], [23], [2], [23], [1], [15], [2], [17], [2], [2], [23], [23], [2], [2], [23], [0], [8], [23], [8], [23], [16], [1], [2], [2], [2], [2], [2], [16], [23], [2], [23], [2], [1], [1], [2], [14], [16], [12], [23], [14], [14], [12], [2], [14], [23], [8], [10], [10], [2], [23], [2], [2], [2], [12], [16], [23], [2], [2], [23], [16], [2], [23], [14], [2], [23], [2], [2], [12], [23], [2], [2], [23], [2], [2], [23], [2], [2], [2], [23], [2], [2], [14], [2], [2], [23], [2], [2], [2], [23], [10], [2], [14], [23], [2], [23], [2], [23], [1], [2], [23], [2], [2], [16], [2], [15], [12], [23], [6], [2], [23], [23], [6], [23], [23], [2], [2], [6], [2], [1], [12], [23], [2], [2], [16], [15], [23], [23], [23], [24], [2], [2], [1], [2], [23], [1], [23], [2], [2], [23], [12], [2], [23], [23], [2], [14], [23], [2], [23], [2], [23], [12], [2], [23], [2], [2], [23], [16], [23], [2], [2], [1], [2], [2], [23], [23], [2], [23], [2], [23], [23], [23], [2], [2], [2], [23], [2], [2], [2], [16], [2], [23], [2], [2], [2], [23], [2], [2], [23], [16], [23], [2], [6], [23], [23], [2], [23], [15], [23], [12], [16], [23], [23], [16], [2], [2], [23], [16], [2], [2], [1], [2], [23], [23], [2], [23], [23], [23], [2], [2], [23], [23], [23], [1], [23], [1], [23], [23], [23], [23], [23], [2], [23], [6], [2], [6], [12], [1], [23], [2], [23], [2], [23], [1], [2], [2], [23], [2], [23], [23], [2], [2], [12], [2], [2], [2], [23], [1], [2], [23], [23], [23], [2], [1], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [2], [10], [16], [23], [1], [23], [23], [14], [23], [12], [23], [2], [2], [23], [23], [23], [2], [23], [2], [16], [23], [23], [1], [2], [23], [23], [2], [2], [23], [2], [2], [2], [2], [12], [12], [23], [23], [23], [1], [23], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [23], [2], [23], [23], [2], [2], [23], [2], [23], [2], [23], [23], [23], [23], [2], [23], [2], [2], [2], [14], [23], [23], [23], [23], [14], [4], [23], [23], [14], [23], [2], [23], [23], [23], [14], [2], [23], [2], [2], [23], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [6], [15], [23], [2], [2], [2], [14], [10], [10], [10], [23], [2], [23], [2], [23], [2], [23], [2], [9], [2], [2], [14], [10], [12], [12], [12], [2], [12], [23], [13], [23], [23], [23], [23], [14], [23], [23], [23], [2], [23], [2], [2], [2], [14], [2], [23], [23], [23], [2], [14], [2], [10], [23], [2], [2], [23], [1], [2], [23], [2], [23], [23], [23], [10], [10], [2], [1], [23], [23], [23], [8], [2], [23], [23], [2], [24], [2], [2], [23], [23], [23], [23], [2], [23], [23], [23], [2], [2], [23], [23], [2], [23], [23], [23], [23], [23], [23], [23], [23], [23], [23], [2], [2], [23], [2], [23], [16], [2], [23], [23], [2], [10], [1], [2], [2], [23], [16], [2], [2], [2], [10], [1], [23], [2], [2], [8], [23], [23], [2], [24], [23], [5], [2], [15], [23], [14], [2], [2], [14], [2], [23], [14], [16], [2], [2], [2], [2], [2], [2], [6], [2], [10], [2], [14], [23], [23], [2], [12], [2], [2], [2], [2], [16], [23], [23], [23], [2], [10], [10], [2], [23], [2], [10], [12], [23], [2], [23], [2], [1], [6], [2], [23], [23], [2], [23], [23], [14], [2], [23], [2], [1], [23], [2], [2], [2], [16], [2], [2], [14], [23], [2], [2], [2], [23], [5], [23], [2], [2], [15], [23], [2], [2], [14], [23], [1], [5], [2], [12], [14], [23], [2], [14], [23], [23], [23], [2], [12], [23], [2], [23], [2], [23], [2], [23], [2], [23], [23], [2], [2], [2], [10], [2], [2], [2], [23], [2], [2], [2], [24], [16], [2], [2], [2], [23], [2], [14], [23], [2], [2], [14], [10], [16], [23], [23], [23], [2], [16], [23], [23], [23], [2], [2], [23], [23], [16], [2], [15], [2], [12], [23], [16], [1], [2], [15], [2], [2], [14], [23], [23], [2], [2], [23], [2], [2], [23], [23], [2], [2], [1], [1], [23], [23], [2], [16], [16], [2], [1], [2], [23], [2], [14], [23], [1], [2], [16], [12], [15], [2], [2], [23], [2], [23], [2], [2], [21], [2], [2], [2], [14], [2], [23], [5], [2], [2], [2], [23], [23], [2], [2], [2], [2], [1], [23], [23], [2], [5], [23], [9], [23], [2], [2], [1], [2], [23], [2], [2], [23], [1], [23], [14], [23], [14], [2], [23], [14], [2], [2], [0], [23], [2], [23], [2], [12], [23], [2], [23], [2], [2], [23], [23], [16], [2], [2], [23], [2], [2], [23], [2], [2], [10], [12], [23], [2], [23], [23], [2], [2], [16], [23], [15], [2], [14], [23], [2], [1], [23], [23], [23], [2], [23], [1], [2], [14], [23], [23], [12], [23], [23], [23], [23], [16], [16], [16], [2], [23], [23], [2], [2], [2], [23], [23], [2], [14], [16], [2], [2], [10], [23], [14], [14], [23], [12], [12], [2], [2], [2], [16], [23], [2], [2], [2], [14], [23], [23], [2], [2], [23], [2], [23], [14], [24], [10], [5], [23], [23], [2], [2], [6], [23], [2], [2], [2], [2], [2], [6], [23], [23], [6], [23], [23], [2], [2], [12], [2], [23], [2], [2], [23], [2], [23], [2], [16], [1], [23], [23], [23], [23], [23], [10], [10], [23], [2], [2], [2], [2], [2], [14], [2], [2], [2], [23], [23], [23], [14], [2], [12], [2], [2], [23], [2], [14], [10], [10], [2], [2], [23], [10], [10], [23], [2], [10], [10], [2], [10], [10], [10], [12], [23], [23], [2], [23], [2], [23], [2], [12], [2], [2], [2], [23], [23], [2], [14], [2], [10], [10], [2], [14], [2], [2], [10], [23], [23], [2], [2], [12], [23], [12], [16], [2], [23], [2], [2], [12], [2], [2], [2], [23], [2], [2], [12], [10], [1], [2], [23], [23], [23], [10], [2], [23], [6], [2], [2], [2], [10], [2], [23], [23], [2], [23], [10], [23], [2], [2], [10], [10], [23], [2], [10], [23], [10], [10], [23], [10], [23], [2], [10], [2], [23], [2], [2], [10], [23], [2], [23], [10], [23], [23], [2], [10], [2], [2], [2], [16], [23], [23], [14], [16], [2], [2], [2], [23], [14], [10], [9], [14], [2], [2], [12], [23], [2], [2], [21], [2], [23], [23], [15], [1], [2], [14], [23], [2], [2], [23], [10], [2], [23], [23], [2], [23], [23], [10], [2], [2], [15], [2], [23], [23], [2], [1], [2], [23], [2], [12], [23], [23], [23], [14], [2], [0], [25], [2], [10], [2], [10], [16], [14], [2], [1], [2], [10], [23], [2], [2], [2], [16], [14], [2], [2], [2], [23], [2], [10], [23], [2], [23], [23], [23], [9], [1], [2], [2], [2], [23], [2], [2], [2], [2], [23], [1], [23], [2], [2], [2], [2], [23], [15], [23], [16], [2], [23], [2], [23], [1], [23], [23], [2], [23], [2], [23], [24], [23], [2], [14], [21], [2], [23], [23], [2], [2], [24], [7], [2], [2], [23], [7], [2], [2], [2], [2], [2], [2], [2], [0], [10], [14], [0], [23], [12], [8], [14], [2], [2], [14], [2], [2], [2], [8], [2], [2], [2], [2], [2], [8], [12], [2], [2], [14], [2], [2], [14], [14], [2], [2], [14], [23], [10], [10], [10], [23], [14], [14], [2], [2], [2], [2], [23], [2], [14], [14], [14], [2], [2], [23], [2], [23], [2], [2], [23], [2], [2], [23], [2], [23], [23], [23], [10], [10], [23], [23], [23], [2], [2], [23], [14], [2], [2], [2], [23], [2], [23], [2], [2], [23], [2], [23], [2], [23], [23], [2], [1], [10], [14], [10], [23], [10], [10], [2], [10], [23], [16], [2], [23], [0], [23], [2], [14], [2], [23], [2], [23], [23], [2], [2], [2], [2], [3], [23], [12], [23], [2], [2], [2], [2], [3], [2], [15], [23], [2], [2], [2], [2], [2], [23], [12], [2], [2], [2], [2], [1], [12], [2], [2], [16], [2], [23], [2], [10], [10], [2], [23], [10], [23], [23], [23], [14], [12], [1], [2], [2], [14], [2], [23], [2], [2], [16], [15], [2], [2], [12], [2], [2], [2], [23], [2], [1], [2], [4], [2], [14], [10], [23], [2], [23], [14], [23], [2], [2], [12], [2], [23], [2], [23], [2], [23], [23], [2], [2], [2], [23], [14], [2], [2], [23], [23], [2], [14], [2], [2], [1], [2], [23], [2], [2], [2], [23], [2], [14], [2], [10], [2], [23], [12], [2], [2], [23], [2], [23], [23], [23], [2], [23], [2], [2], [23], [1], [2], [1], [2], [23], [0], [23], [12], [6], [23], [23], [5], [2], [14], [2], [2], [23], [2], [16], [2], [10], [2], [2], [2], [2], [2], [1], [23], [2], [1], [2], [23], [2], [2], [23], [2], [2], [23], [2], [18], [23], [2], [23], [2], [23], [2], [2], [23], [2], [23], [2], [2], [14], [12], [2], [23], [2], [14], [2], [2], [23], [2], [23], [15], [10], [23], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [23], [2], [14], [2], [2], [15], [2], [14], [2], [2], [2], [2], [15], [2], [23], [2], [23], [23], [2], [2], [2], [23], [14], [2], [2], [23], [23], [23], [2], [2], [16], [10], [23], [23], [2], [23], [23], [2], [2], [23], [2], [2], [2], [2], [2], [2], [1], [23], [2], [2], [2], [2], [23], [23], [23], [2], [2], [2], [2], [23], [1], [23], [2], [2], [23], [2], [2], [23], [1], [23], [2], [2], [2], [23], [2], [14], [23], [14], [2], [23], [2], [23], [2], [23], [14], [23], [14], [1], [2], [16], [23], [2], [2], [14], [2], [24], [23], [2], [2], [2], [14], [2], [23], [10], [2], [2], [2], [2], [23], [2], [2], [2], [16], [23], [2], [23], [2], [23], [23], [2], [2], [23], [2], [2], [2], [14], [2], [23], [2], [14], [23], [15], [2], [14], [23], [23], [23], [12], [23], [23], [23], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [12], [1], [2], [2], [2], [2], [2], [2], [14], [14], [23], [2], [1], [2], [12], [23], [2], [2], [12], [2], [16], [14], [2], [2], [2], [23], [15], [12], [23], [9], [12], [2], [23], [10], [2], [2], [2], [14], [23], [2], [16], [2], [23], [2], [2], [2], [23], [12], [2], [2], [2], [12], [2], [2], [2], [23], [14], [2], [23], [1], [23], [2], [14], [2], [2], [2], [17], [10], [2], [23], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [15], [2], [2], [2], [2], [16], [23], [12], [1], [10], [2], [14], [2], [2], [2], [2], [2], [2], [2], [16], [10], [2], [23], [2], [2], [14], [2], [2], [2], [2], [14], [2], [10], [1], [2], [2], [14], [23], [2], [2], [23], [23], [2], [23], [2], [2], [12], [2], [23], [12], [2], [2], [2], [10], [2], [2], [2], [23], [2], [2], [23], [16], [2], [2], [23], [2], [12], [2], [16], [2], [2], [23], [14], [23], [23], [23], [23], [2], [2], [16], [23], [23], [2], [2], [2], [2], [23], [12], [12], [2], [23], [16], [2], [23], [14], [16], [2], [2], [14], [16], [2], [23], [1], [23], [2], [2], [2], [2], [23], [2], [23], [3], [2], [2], [2], [23], [2], [2], [2], [23], [2], [23], [2], [2], [23], [14], [23], [23], [18], [2], [23], [1], [23], [23], [2], [2], [23], [2], [2], [23], [10], [2], [23], [2], [10], [2], [23], [2], [2], [2], [2], [2], [23], [2], [23], [2], [2], [23], [2], [2], [2], [2], [23], [2], [12], [16], [23], [23], [2], [23], [2], [14], [2], [23], [2], [2], [2], [2], [23], [23], [23], [2], [23], [23], [16], [2], [12], [15], [23], [23], [2], [23], [23], [23], [2], [2], [2], [23], [10], [23], [12], [2], [2], [2], [23], [2], [2], [16], [2], [12], [2], [2], [2], [2], [23], [23], [23], [10], [23], [2], [23], [23], [14], [2], [23], [12], [2], [2], [23], [23], [23], [2], [2], [23], [2], [2], [14], [23], [2], [2], [23], [2], [2], [23], [23], [2], [23], [2], [23], [23], [23], [2], [2], [2], [23], [2], [23], [23], [0], [23], [2], [2], [16], [10], [14], [0], [2], [16], [2], [1], [23], [2], [2], [2], [2], [1], [2], [2], [2], [16], [23], [14], [2], [2], [2], [2], [23], [5], [23], [14], [23], [23], [23], [2], [12], [2], [23], [23], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [14], [23], [23], [2], [9], [23], [2], [2], [23], [23], [2], [23], [23], [2], [2], [2], [2], [5], [2], [23], [2], [2], [23], [23], [14], [14], [23], [23], [2], [2], [23], [14], [23], [23], [10], [23], [23], [2], [23], [10], [14], [23], [10], [2], [2], [0], [10], [2], [2], [14], [12], [23], [1], [10], [12], [2], [9], [2], [2], [23], [2], [12], [2], [2], [12], [16], [2], [2], [2], [2], [23], [5], [2], [2], [2], [2], [16], [10], [9], [10], [2], [14], [10], [2], [2], [10], [2], [10], [2], [10], [10], [10], [2], [10], [12], [2], [2], [2], [23], [2], [2], [2], [2], [10], [2], [2], [2], [2], [2], [23], [2], [2], [23], [2], [2], [23], [2], [2], [23], [23], [12], [15], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [12], [2], [10], [10], [10], [12], [10], [10], [2], [10], [23], [2], [2], [14], [2], [2], [2], [2], [2], [2], [9], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [14], [2], [2], [0], [2], [2], [0], [0], [23], [23], [2], [2], [2], [2], [23], [23], [23], [2], [2], [14], [2], [0], [0], [14], [23], [23], [2], [23], [15], [2], [23], [14], [23], [2], [23], [23], [2], [2], [2], [2], [2], [2], [23], [2], [2], [23], [23], [2], [23], [2], [2], [2], [2], [2], [16], [2], [2], [2], [2], [2], [2], [2], [16], [2], [2], [2], [2], [23], [2], [23], [23], [23], [2], [2], [2], [2], [2], [2], [23], [23], [2], [2], [23], [10], [23], [2], [2], [2], [23], [14], [2], [23], [2], [14], [2], [0], [8], [23], [23], [23], [2], [23], [23], [2], [23], [2], [2], [2], [2], [16], [2], [2], [23], [2], [16], [23], [2], [16], [2], [23], [23], [2], [16], [2], [23], [2], [23], [16], [23], [2], [2], [2], [2], [23], [2], [2], [8], [2], [23], [2], [2], [23], [2], [14], [2], [2], [2], [2], [23], [2], [2], [2], [23], [2], [23], [14], [2], [14], [14], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [1], [10], [23], [0], [23], [12], [2], [12], [2], [2], [0], [14], [2], [2], [23], [14], [2], [23], [10], [10], [2], [2], [10], [10], [10], [10], [10], [23], [2], [14], [12], [10], [14], [14], [10], [10], [2], [2], [23], [12], [2], [2], [2], [23], [2], [2], [2], [2], [2], [14], [2], [2], [23], [23], [2], [16], [2], [2], [14], [2], [23], [2], [2], [2], [23], [2], [23], [14], [2], [2], [23], [2], [2], [2], [1], [2], [1], [23], [2], [2], [16], [10], [2], [14], [23], [23], [23], [14], [14], [23], [2], [2], [2], [1], [2], [23], [2], [14], [2], [23], [0], [23], [2], [23], [14], [23], [10], [23], [2], [2], [2], [23], [23], [4], [23], [15], [2], [2], [16], [16], [15], [23], [2], [15], [2], [21], [23], [10], [10], [2], [10], [2], [10], [14], [2], [23], [10], [23], [2], [2], [12], [23], [1], [2], [2], [10], [23], [1], [2], [1], [2], [2], [2], [2], [23], [23], [23], [2], [2], [14], [2], [2], [23], [2], [2], [2], [10], [2], [2], [23], [2], [2], [12], [2], [23], [14], [2], [2], [2], [2], [2], [23], [2], [10], [23], [2], [2], [2], [2], [2], [10], [2], [23], [23], [23], [23], [23], [23], [23], [2], [1], [2], [23], [23], [23], [23], [2], [2], [10], [2], [2], [2], [2], [10], [2], [2], [12], [2], [23], [2], [23], [2], [2], [2], [15], [2], [23], [2], [2], [2], [2], [23], [14], [2], [2], [2], [2], [2], [23], [2], [23], [2], [23], [14], [12], [12], [1], [23], [0], [23], [23], [2], [23], [23], [2], [2], [14], [2], [2], [12], [2], [14], [2], [2], [23], [2], [23], [2], [21], [14], [23], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [2], [2], [15], [6], [23], [16], [23], [2], [23], [2], [2], [2], [23], [2], [2], [2], [1], [2], [23], [2], [1], [2], [2], [2], [23], [16], [2], [2], [2], [2], [10], [23], [2], [9], [9], [23], [24], [2], [23], [1], [2], [2], [23], [2], [23], [12], [23], [23], [23], [15], [23], [2], [24], [23], [23], [23], [10], [23], [2], [23], [23], [23], [23], [23], [23], [2], [2], [2], [23], [23], [2], [2], [2], [16], [23], [14], [2], [16], [2], [2], [2], [2], [2], [23], [14], [23], [2], [1], [2], [2], [23], [2], [23], [23], [2], [23], [16], [23], [2], [2], [3], [23], [2], [2], [23], [2], [1], [2], [2], [1], [2], [2], [2], [2], [14], [10], [23], [2], [14], [2], [23], [2], [10], [10], [14], [23], [2], [2], [2], [14], [14], [21], [2], [23], [2], [23], [23], [23], [23], [2], [23], [2], [2], [23], [2], [2], [2], [23], [2], [2], [23], [2], [2], [2], [0], [2], [23], [2], [14], [12], [1], [2], [14], [2], [2], [2], [23], [23], [23], [2], [23], [10], [23], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [23], [2], [2], [2], [6], [2], [2], [2], [2], [2], [2], [23], [23], [23], [23], [2], [23], [2], [2], [23], [2], [23], [2], [2], [0], [2], [2], [2], [2], [2], [2], [23], [23], [10], [10], [14], [10], [15], [2], [10], [10], [2], [10], [2], [10], [23], [21], [2], [2], [0], [23], [23], [2], [23], [16], [10], [2], [2], [10], [14], [2], [10], [23], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [12], [2], [2], [2], [2], [14], [1], [23], [23], [15], [23], [10], [10], [10], [2], [10], [2], [10], [2], [2], [2], [10], [2], [2], [17], [2], [10], [23], [10], [10], [23], [10], [10], [10], [23], [2], [2], [0], [23], [2], [0], [2], [2], [10], [1], [2], [2], [23], [0], [2], [23], [2], [1], [2], [2], [10], [10], [10], [2], [10], [10], [10], [10], [23], [10], [2], [10], [10], [10], [10], [10], [10], [2], [10], [2], [2], [15], [2], [10], [10], [10], [2], [10], [10], [10], [10], [10], [10], [17], [10], [10], [10], [10], [10], [2], [10], [23], [2], [0], [2], [2], [10], [2], [10], [10], [0], [2], [10], [2], [2], [10], [2], [2], [10], [2], [10], [10], [10], [10], [14], [23], [16], [14], [10], [14], [10], [10], [9], [10], [10], [10], [2], [23], [2], [2], [2], [2], [2], [14], [2], [2], [21], [23], [0], [12], [2], [2], [2], [2], [2], [2], [23], [2], [23], [23], [2], [2], [2], [2], [2], [23], [2], [23], [2], [23], [2], [2], [6], [23], [2], [2], [2], [2], [2], [0], [2], [2], [2], [2], [2], [10], [2], [2], [2], [23], [2], [24], [1], [2], [2], [2], [23], [23], [2], [2], [23], [0], [2], [2], [2], [10], [2], [2], [14], [2], [2], [2], [23], [2], [2], [23], [2], [2], [12], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [9], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [23], [23], [2], [2], [2], [0], [23], [23], [10], [2], [2], [2], [10], [10], [2], [23], [0], [2], [2], [2], [2], [2], [14], [23], [2], [2], [23], [12], [0], [23], [23], [14], [1], [10], [2], [2], [2], [2], [23], [2], [23], [2], [2], [2], [23], [2], [10], [2], [10], [2], [23], [2], [2], [2], [2], [2], [2], [2], [0], [16], [23], [23], [2], [2], [2], [2], [2], [23], [23], [2], [2], [0], [14], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [2], [2], [2], [15], [2], [15], [15], [23], [23], [2], [14], [2], [2], [23], [23], [2], [2], [14], [16], [2], [2], [2], [4], [2], [2], [2], [23], [23], [2], [0], [4], [2], [23], [23], [2], [2], [2], [2], [0], [16], [23], [23], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [23], [14], [2], [2], [2], [15], [2], [2], [2], [2], [23], [2], [2], [2], [23], [0], [2], [2], [2], [23], [9], [2], [24], [2], [0], [9], [9], [2], [10], [0], [2], [2], [2], [23], [2], [9], [23], [2], [2], [23], [23], [2], [1], [2], [9], [23], [2], [23], [2], [2], [10], [23], [2], [2], [2], [2], [10], [2], [2], [23], [2], [2], [0], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [9], [10], [23], [2], [2], [2], [2], [10], [2], [23], [14], [15], [2], [2], [23], [23], [23], [2], [16], [2], [2], [23], [2], [2], [23], [2], [2], [14], [2], [2], [16], [2], [9], [2], [9], [2], [2], [0], [15], [2], [9], [2], [9], [0], [14], [2], [2], [2], [23], [23], [2], [23], [9], [1], [14], [14], [14], [16], [2], [1], [2], [2], [2], [16], [2], [2], [2], [16], [23], [14], [14], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [14], [23], [2], [2], [2], [10], [2], [12], [12], [2], [23], [14], [2], [23], [14], [14], [14], [2], [2], [2], [2], [2], [2], [2], [2], [23], [2], [23], [23], [23], [2], [14], [2], [2], [2], [2], [1], [23], [1], [23], [23], [2], [2], [23], [2], [2], [2], [3], [14], [2], [2], [23], [2], [2], [23], [23], [14], [14], [23], [14], [14], [2], [2], [2], [23], [2], [23], [2], [2], [2], [2], [10], [0], [2], [2], [2], [14], [2], [14], [2], [2], [23], [0], [2], [2], [2], [0], [2], [2], [2], [2], [2], [23], [21], [2], [2], [0], [2], [2], [2], [2], [10], [0], [16], [23], [23], [2], [2], [2], [2], [9], [1], [2], [2], [9], [23], [10], [2], [2], [23], [10], [2], [2], [2], [0], [0], [23], [2], [2], [2], [2], [23], [2], [2], [2], [2], [2], [23], [2], [23], [10], [2], [2], [2], [2], [2], [14], [2], [2], [2], [2], [2], [2], [2], [2], [14], [23], [0], [23], [2], [2], [2], [23], [2], [23], [2], [2], [16], [14], [2], [12], [0], [23], [1], [2], [0], [23], [2], [23], [4], [23], [14], [10], [10], [10], [23], [14], [2], [10], [12], [2], [2], [2], [2], [14], [14], [23], [23], [23], [14], [14], [14], [23], [2], [14], [23], [23], [16], [2], [2], [2], [0], [2], [2], [14], [2], [23], [2], [23], [16], [2], [2], [1], [2], [2], [2], [14], [2], [2], [2], [0], [23], [2], [2], [2], [12], [14], [2], [2], [0], [0], [4], [1], [2], [2], [2], [2], [2], [9], [0], [2], [16], [2], [2], [2], [14], [2], [2], [14], [2], [16], [2], [12], [2], [0], [2], [2], [10], [0], [2], [2], [2], [2], [2], [2], [2], [23], [2], [10], [14], [23], [2], [23], [0], [23], [23], [2], [2], [2], [2], [2], [2], [2], [23], [23], [2], [14], [4], [23], [0], [2], [14], [2], [2], [2], [2], [23], [23], [1], [2], [2], [2], [2], [2], [14], [2], [14], [16], [2], [16], [2], [2], [2], [2], [2], [2], [9], [2], [14], [2], [14], [14], [2], [23], [2], [2], [10], [2], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [2], [10], [10], [23], [2], [2], [2], [2], [14], [2], [0], [2], [10], [23], [9], [2], [2], [0], [20], [2], [23], [23], [2], [0], [2], [1], [16], [12], [2], [2], [2], [2], [2], [2], [23], [23], [2], [12], [16], [9], [0], [9], [9], [14], [16], [23], [9], [9], [0], [23], [2], [2], [2], [2], [2], [2], [2], [12], [23], [2], [9], [2], [23], [23], [23], [9], [2], [14], [2], [2], [2], [14], [2], [23], [2], [15], [2], [23], [2], [2], [2], [2], [23], [2], [2], [2], [23], [23], [23], [23], [16], [14], [2], [23], [23], [23], [2], [23], [2], [1], [2], [2], [23], [2], [2], [2], [14], [23], [14], [2], [2], [23], [2], [16], [2], [2], [23], [2], [23], [2], [2], [2], [0], [23], [23], [10], [1], [2], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [2], [2], [23], [23], [23], [23], [2], [2], [23], [2], [10], [23], [23], [23], [23], [0], [23], [10], [23], [14], [2], [23], [16], [2], [0], [0], [2], [23], [2], [23], [10], [2], [2], [2], [2], [23], [21], [16], [10], [15], [14], [23], [2], [2], [23], [2], [2], [2], [15], [23], [15], [2], [23], [15], [1], [10], [2], [23], [23], [2], [2], [2], [2], [14], [2], [0], [2], [23], [2], [0], [23], [2], [9], [2], [2], [2], [2], [12], [2], [2], [2], [2], [14], [23], [14], [14], [23], [23], [2], [2], [2], [15], [2], [12], [2], [12], [2], [23], [2], [2], [2], [2], [23], [2], [23], [2], [2], [14], [2], [10], [2], [10], [2], [2], [2], [10], [0], [1], [2], [23], [10], [2], [2], [2], [2], [10], [23], [2], [15], [2], [14], [0], [2], [10], [2], [2], [10], [2], [2], [23], [5], [16], [2], [14], [23], [23], [2], [2], [2], [0], [0], [23], [0], [2], [2], [2], [23], [2], [2], [2], [2], [1], [23], [0], [23], [2], [7], [2], [2], [23], [2], [2], [2], [2], [2], [2], [2], [9], [2], [23], [2], [2], [2], [0], [9], [16], [2], [2], [25], [23], [2], [23], [2], [12], [23], [23], [14], [2], [23], [2], [23], [2], [23], [12], [15], [2], [2], [2], [23], [2], [0], [1], [2], [2], [23], [2], [2], [23], [0], [2], [10], [23], [2], [1], [2], [2], [2], [0], [23], [14], [2], [23], [2], [2], [23], [2], [2], [12], [23], [2], [2], [10], [2], [2], [2], [10], [2], [23], [23], [23], [23], [23], [23], [23], [23], [2], [23], [2], [2], [2], [10], [2], [2], [10], [2], [2], [2], [2], [14], [2], [2], [23], [2], [2], [2], [2], [2], [23], [10], [2], [10], [14], [2], [10], [10], [10], [10], [10], [2], [23], [2], [14], [2], [2], [2], [2], [2], [2], [2], [2], [2], [1], [2], [2], [2], [2], [14], [23], [23], [1], [2], [23], [2], [5], [14], [2], [5], [23], [2], [23], [2], [2], [23], [2], [2], [2], [2], [2], [23], [14], [2], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [10], [23], [16], [2], [2], [23], [2], [2], [2], [2], [23], [10], [2], [0], [2], [2]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] дом подьезда имеет подъезд лестница от снега вычещина а богом забытый что за привелегия для мы тоже люди почему я должна идти на другой край дома [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18864 4717\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gt), len(test_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#модель от Сбербанка\\nmodel_dir = \\'/notebooks/bert_model_from_sber/\\'\\nmodel_name = \\'sbert_cased_L-24_H-1024_A-16_pytorch.zip\\'\\nurl = r\"https://storage.googleapis.com/bert_resourses/sbert_nlu/sbert_cased_L-24_H-1024_A-16_pytorch.zip\"\\nmodel_path = r\\'/notebooks/bert_model_from_sber/cased_L-24_H-1024_A-16_pytorch\\'\\n\\n#модель RUBERT deeppavlov\\nmodel_dir = \\'/notebooks/RUBERT_deeppavlov/\\'\\nmodel_name = \\'rubert_cased_L-12_H-768_A-12_pt.tar.gz\\'\\nurl = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\"\\nmodel_path = r\\'/notebooks/RUBERT_deeppavlov/rubert_cased_L-12_H-768_A-12_pt\\'\\n\\n#модель RUBERT deeppavlov предложения\\nmodel_dir = \\'/notebooks/RUBERT_deeppavlov_sentence/\\'\\nmodel_name = \\'sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz\\'\\nurl = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz\"\\nmodel_path = r\\'/notebooks/RUBERT_deeppavlov_sentence/sentence_ru_cased_L-12_H-768_A-12_pt\\'\\n\\n#модель RUBERT deeppavlov разговорный\\nmodel_dir = \\'/notebooks/RUBERT_deeppavlov_conversational/\\'\\nmodel_name = \\'conversational_cased_L-12_H-768_A-12_pt.tar.gz\\'\\nurl = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/conversational_cased_L-12_H-768_A-12_pt.tar.gz\"\\nmodel_path = r\\'/notebooks/RUBERT_deeppavlov_conversational/conversational_cased_L-12_H-768_A-12_pt\\'\\n\\n#модель BERT мультиязычный deeppavlov\\nmodel_dir = \\'/notebooks/BERT_deeppavlov_multi/\\'\\nmodel_name = \\'sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz\\'\\nurl = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz\"\\nmodel_path = r\\'/notebooks/BERT_deeppavlov_multi/sentence_multi_cased_L-12_H-768_A-12_pt\\'\\n\\n\\n# Create output directory if needed\\nif not os.path.exists(model_dir):\\n    os.makedirs(model_dir)\\n    path = Path(model_name)\\n    f=open(os.path.join(model_dir, model_name), \"ab+\") #открываем файл для записи, в режиме wb\\n    ufr = requests.get(url) #делаем запрос\\n    f.write(ufr.content) #записываем содержимое в файл; как видите - content запроса\\n    f.close()\\n    \\n    if path.suffix == \".gz\":\\n        tar = tarfile.open(os.path.join(model_dir, model_name), \"r:gz\")\\n        tar.extractall(model_dir)\\n        tar.close()\\n    elif path.suffix == \".tar\":\\n        tar = tarfile.open(os.path.join(model_dir, model_name), \"r:\")\\n        tar.extractall(model_dir)\\n        tar.close()\\n    elif path.suffix == \".zip\":    \\n        dir_zip = zipfile.ZipFile(os.path.join(model_dir, model_name))\\n        dir_zip.extractall(model_dir)\\n        dir_zip.close()\\n                              \\n    os.remove(os.path.join(model_dir, model_name))   \\n    \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#скачиваем модели BERT\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\"\"\"\n",
    "#модель от Сбербанка\n",
    "model_dir = '/notebooks/bert_model_from_sber/'\n",
    "model_name = 'sbert_cased_L-24_H-1024_A-16_pytorch.zip'\n",
    "url = r\"https://storage.googleapis.com/bert_resourses/sbert_nlu/sbert_cased_L-24_H-1024_A-16_pytorch.zip\"\n",
    "model_path = r'/notebooks/bert_model_from_sber/cased_L-24_H-1024_A-16_pytorch'\n",
    "\n",
    "#модель RUBERT deeppavlov\n",
    "model_dir = '/notebooks/RUBERT_deeppavlov/'\n",
    "model_name = 'rubert_cased_L-12_H-768_A-12_pt.tar.gz'\n",
    "url = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\"\n",
    "model_path = r'/notebooks/RUBERT_deeppavlov/rubert_cased_L-12_H-768_A-12_pt'\n",
    "\n",
    "#модель RUBERT deeppavlov предложения\n",
    "model_dir = '/notebooks/RUBERT_deeppavlov_sentence/'\n",
    "model_name = 'sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz'\n",
    "url = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz\"\n",
    "model_path = r'/notebooks/RUBERT_deeppavlov_sentence/sentence_ru_cased_L-12_H-768_A-12_pt'\n",
    "\n",
    "#модель RUBERT deeppavlov разговорный\n",
    "model_dir = '/notebooks/RUBERT_deeppavlov_conversational/'\n",
    "model_name = 'conversational_cased_L-12_H-768_A-12_pt.tar.gz'\n",
    "url = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/conversational_cased_L-12_H-768_A-12_pt.tar.gz\"\n",
    "model_path = r'/notebooks/RUBERT_deeppavlov_conversational/conversational_cased_L-12_H-768_A-12_pt'\n",
    "\n",
    "#модель BERT мультиязычный deeppavlov\n",
    "model_dir = '/notebooks/BERT_deeppavlov_multi/'\n",
    "model_name = 'sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz'\n",
    "url = r\"http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_multi_cased_L-12_H-768_A-12_pt.tar.gz\"\n",
    "model_path = r'/notebooks/BERT_deeppavlov_multi/sentence_multi_cased_L-12_H-768_A-12_pt'\n",
    "\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    path = Path(model_name)\n",
    "    f=open(os.path.join(model_dir, model_name), \"ab+\") #открываем файл для записи, в режиме wb\n",
    "    ufr = requests.get(url) #делаем запрос\n",
    "    f.write(ufr.content) #записываем содержимое в файл; как видите - content запроса\n",
    "    f.close()\n",
    "    \n",
    "    if path.suffix == \".gz\":\n",
    "        tar = tarfile.open(os.path.join(model_dir, model_name), \"r:gz\")\n",
    "        tar.extractall(model_dir)\n",
    "        tar.close()\n",
    "    elif path.suffix == \".tar\":\n",
    "        tar = tarfile.open(os.path.join(model_dir, model_name), \"r:\")\n",
    "        tar.extractall(model_dir)\n",
    "        tar.close()\n",
    "    elif path.suffix == \".zip\":    \n",
    "        dir_zip = zipfile.ZipFile(os.path.join(model_dir, model_name))\n",
    "        dir_zip.extractall(model_dir)\n",
    "        dir_zip.close()\n",
    "                              \n",
    "    os.remove(os.path.join(model_dir, model_name))   \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Z474sSC6oe7A",
    "outputId": "fbaa8fd8-bccd-4feb-ce52-beba5d293cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'п', '##о', '##с', '##л', '##е', 'у', '##с', '##т', '##ан', '##ов', '##к', '##и', 'м', '##у', '##с', '##о', '##р', 'п', '##л', '##о', '##щ', '##а', '##д', '##к', '##и', 'н', '##а', '##ш', '##а', 'у', '##л', '##и', '##ц', '##а', 'п', '##р', '##е', '##в', '##р', '##а', '##т', '##и', '##л', '##а', '##с', '##ь', 'в', 'с', '##в', '##а', '##л', '##к', '##у', 'о', '##д', '##и', '##н', 'к', '##о', '##н', '##т', '##е', '##и', '##н', '##е', '##р', 'н', '##е', 'с', '##п', '##р', '##а', '##в', '##л', '##я', '##е', '##т', '##с', '##я', 'с', 'м', '##у', '##с', '##о', '##р', '##о', '##м', 'к', '##о', '##т', '##о', '##р', '##ы', '##и', 'в', '##е', '##з', '##у', '##т', 'и', '##з', 'с', '##о', '##с', '##е', '##д', '##н', '##и', '##х', 'п', '##о', '##с', '##е', '##л', '##к', '##ов', 'м', '##у', '##с', '##о', '##р', 'р', '##а', '##з', '##л', '##е', '##т', '##а', '##е', '##т', '##с', '##я', 'и', 'р', '##а', '##з', '##н', '##о', '##с', '##и', '##т', '##с', '##я', 'с', '##о', '##б', '##а', '##ка', '##м', '##и', 'п', '##р', '##и', '##л', '##е', '##г', '##а', '##ю', '##щ', '##а', '##я', 'т', '##е', '##р', '##р', '##и', '##т', '##о', '##р', '##ия', 'в', '##с', '##я', 'в', 'м', '##у', '##с', '##о', '##р', '##е', 'п', '##р', '##о', '##с', '##и', '##м', 'п', '##р', '##и', '##н', '##я', '##т', '##ь', 'м', '##е', '##р', '##ы', 'п', '##о', 'у', '##с', '##т', '##р', '##ан', '##е', '##н', '##и', '##ю', 'д', '##ан', '##н', '##о', '##и', 'п', '##р', '##о', '##б', '##л', '##е', '##м', '##ы', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#загружаем токенизатор BERT и разбиваем текст на токены\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
    "print (tokenized_texts[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87_kXUeT2-br"
   },
   "source": [
    "BERTу нужно предоставить специальный формат входных данных.\n",
    "\n",
    "\n",
    "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
    "- **labels**: выходные метки\n",
    "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
    "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cp9BPRd1tMIo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21870 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21958 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21702 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3613 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8289 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4784 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7852 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5501 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (17987 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (19620 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7857 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3343 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21461 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1922 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2236 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21851 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5946 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (20211 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (11766 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21872 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=50,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  1192 10260  1184 14150 16856 14150 29741 15290  1190 15290 29743\n",
      " 10325 22919  1181 15290 22919 14150 18947 19865 17432  1194 29436 10325\n",
      " 22919 10260  1192 15290 29746 14150 18947 17432 22919 18947 14150  1185\n",
      " 15290  1192 10260 29744 19865 29752 15290 18947 10325 15290  1189 10260\n",
      " 23925  1181]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFbE-UHvsb7-"
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, train_gt, \n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jw5K2A5Ko1RF"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15],\n",
       "        [23],\n",
       "        [19],\n",
       "        ...,\n",
       "        [14],\n",
       "        [ 2],\n",
       "        [ 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание загрузчиков данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEgLpFVlo1Z-"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler=SequentialSampler(validation_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNl8khAhPYju"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные модели есть и для других задач:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFsCTp_mporB",
    "outputId": "dd067229-1925-4b37-f517-0c14e25420d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=num_labels) #\"bert-base-uncased\"\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 393 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 1024)\n",
      "bert.embeddings.position_embeddings.weight               (512, 1024)\n",
      "bert.embeddings.token_type_embeddings.weight               (2, 1024)\n",
      "bert.embeddings.LayerNorm.weight                             (1024,)\n",
      "bert.embeddings.LayerNorm.bias                               (1024,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.0.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.0.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.0.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.0.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                   (1024,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                (1024, 1024)\n",
      "bert.pooler.dense.bias                                       (1024,)\n",
      "classifier.weight                                         (26, 1024)\n",
      "classifier.bias                                                (26,)\n"
     ]
    }
   ],
   "source": [
    "#посмотрим параметры модели\n",
    "\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда наша модель загружена, нам нужно получить гиперпараметры обучения из сохраненной модели.\n",
    "\n",
    "Для точной настройки авторы рекомендуют выбирать из следующих значений (из Приложения A.3 документа BERT ):\n",
    "\n",
    "Размер партии: 16, 32\n",
    "Скорость обучения (Адам): 5e-5, 3e-5, 2e-5\n",
    "Количество эпох: 2, 3, 4\n",
    "Мы выбрали:\n",
    "\n",
    "Размер партии: 32 (устанавливается при создании наших загрузчиков данных)\n",
    "Скорость обучения: 2e-5\n",
    "Эпох: 4\n",
    "Параметр epsilon eps = 1e-8- это «очень маленькое число, чтобы предотвратить любое деление на ноль в реализации»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, \n",
    "                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вспомогательная функция для вычисления точности\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "6J-FYdx6nFE_",
    "outputId": "8e388ad1-f9db-4c7b-d080-6c0a0e964610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:05\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:08\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:09\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:10\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:12\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:16\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:17\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:18\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:19\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:21\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:22\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:25\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:26\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:29\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:30\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:31\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:33\n",
      "  Batch    40  of    531.    Elapsed: 0:00:33.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:35\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:36\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:43\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:44\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:48\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:49\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:51\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:52\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:56\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:00:57\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:00:58\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:00\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:01\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:02\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:04\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:05\n",
      "  Batch    80  of    531.    Elapsed: 0:01:05.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:13\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:14\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:15\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:18\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:19\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:20\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:22\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:23\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:28\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:33\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:35\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:36\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:37\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:38\n",
      "  Batch   120  of    531.    Elapsed: 0:01:38.\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:40\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:41\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:44\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:45\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:48\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:49\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:50\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:52\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:53\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:54\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:01:58\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:01:59\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:01\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:02\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:08\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:10\n",
      "  Batch   160  of    531.    Elapsed: 0:02:10.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:11\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:12\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:14\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:15\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:16\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:19\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:20\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:21\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:23\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:24\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:29\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:32\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:33\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:37\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:38\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:40\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:41\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:43\n",
      "  Batch   200  of    531.    Elapsed: 0:02:43.\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:45\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:46\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:49\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:02:51\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:02:55\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:02:58\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:11\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:12\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:15\n",
      "  Batch   240  of    531.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:17\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:37\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:39\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:41\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:42\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:43\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:44\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:46\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:47\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:48\n",
      "  Batch   280  of    531.    Elapsed: 0:03:48.\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:50\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:51\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:52\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:03:54\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:03:55\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:03:56\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:03:57\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:03:59\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:00\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:01\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:03\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:04\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:05\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:08\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:09\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:10\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:12\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:13\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:14\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:16\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:17\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:18\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:20\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:20\n",
      "  Batch   320  of    531.    Elapsed: 0:04:20.\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:21\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:22\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:25\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:26\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:27\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:29\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:30\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:31\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:34\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:35\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:36\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:38\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:39\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:40\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:42\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:43\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:44\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:45\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:47\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:48\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:49\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:04:51\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:04:53\n",
      "  Batch   360  of    531.    Elapsed: 0:04:53.\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:04:55\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:04:57\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:04:58\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:02\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:04\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:05\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:06\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:08\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:09\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:10\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:11\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:13\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:15\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:18\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:19\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:21\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:22\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:23\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:24\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:25\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:25\n",
      "  Batch   400  of    531.    Elapsed: 0:05:25.\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:26\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:27\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:28\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:30\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:31\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:32\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:34\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:35\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:36\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:37\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:39\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:40\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:41\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:44\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:45\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:46\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:49\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:05:52\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:05:53\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:05:54\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:05:56\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:05:57\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:05:58\n",
      "  Batch   440  of    531.    Elapsed: 0:05:58.\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:05:59\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:01\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:02\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:03\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:05\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:07\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:10\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:11\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:12\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:14\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:15\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:16\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:18\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:19\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:20\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:23\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:24\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:27\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:28\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:29\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:30\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:30\n",
      "  Batch   480  of    531.    Elapsed: 0:06:30.\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:31\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:32\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:33\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:36\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:37\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:38\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:40\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:41\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:42\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:43\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:43\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:45\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:46\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:49\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:50\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:53\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:06:57\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:06:58\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:06:59\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:03\n",
      "  Batch   520  of    531.    Elapsed: 0:07:03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.73\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "  Average training loss: 1.73\n",
      "  Training epcoh took: 0:07:07\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "  Average training loss: 1.75\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "  Average training loss: 1.75\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.45\n",
      "  Validation Loss: 1.71\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:05\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:08\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:09\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:10\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:12\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:16\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:17\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:18\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:19\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:21\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:22\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:25\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:26\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:29\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:29\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:30\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:31\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "  Batch    40  of    531.    Elapsed: 0:00:33.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:35\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:36\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:43\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:44\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:48\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:49\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:51\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:52\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:56\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:57\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:58\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:00\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:01\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:02\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:04\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:04\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:05\n",
      "  Batch    80  of    531.    Elapsed: 0:01:05.\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:13\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:14\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:15\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:18\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:19\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:20\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:22\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:23\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:28\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:33\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:35\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:37\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:38\n",
      "  Batch   120  of    531.    Elapsed: 0:01:38.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:40\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:41\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:44\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:45\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:48\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:49\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:50\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:52\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:53\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:54\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:58\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:59\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:01\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:02\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:08\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:10\n",
      "  Batch   160  of    531.    Elapsed: 0:02:10.\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:11\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:12\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:14\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:15\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:16\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:19\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:20\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:21\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:23\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:24\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:29\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:32\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:33\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:37\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:38\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:40\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:41\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:43\n",
      "  Batch   200  of    531.    Elapsed: 0:02:43.\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:45\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:46\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:49\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:51\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:55\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:58\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:11\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:12\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:15\n",
      "  Batch   240  of    531.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:17\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:37\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:39\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:41\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:42\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:43\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:44\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:46\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:47\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:48\n",
      "  Batch   280  of    531.    Elapsed: 0:03:48.\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:50\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:51\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:52\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:54\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:55\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:56\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:57\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:59\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:00\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:01\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:03\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:04\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:05\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:08\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:09\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:10\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:12\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:13\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:14\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:16\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:17\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:18\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:20\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:20\n",
      "  Batch   320  of    531.    Elapsed: 0:04:20.\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:21\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:22\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:25\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:26\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:27\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:29\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:30\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:31\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:34\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:35\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:36\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:38\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:39\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:40\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:42\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:43\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:44\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:45\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:47\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:48\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:49\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:51\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:53\n",
      "  Batch   360  of    531.    Elapsed: 0:04:53.\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:55\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:57\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:58\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:02\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:04\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:05\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:06\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:08\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:09\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:10\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:11\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:13\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:15\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:17\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:18\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:19\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:21\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:22\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:23\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:24\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:25\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:25\n",
      "  Batch   400  of    531.    Elapsed: 0:05:25.\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:26\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:27\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:28\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:30\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:31\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:32\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:34\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:35\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:36\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:37\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:39\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:40\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:41\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:44\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:45\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:46\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:46\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:49\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:52\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:53\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:54\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:56\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:57\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:58\n",
      "  Batch   440  of    531.    Elapsed: 0:05:58.\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:59\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:59\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:01\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:02\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:03\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:03\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:05\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:07\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:10\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:11\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:12\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:12\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:14\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:15\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:16\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:16\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:18\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:19\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:20\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:23\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:24\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:27\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:28\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:29\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:30\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:30\n",
      "  Batch   480  of    531.    Elapsed: 0:06:30.\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:31\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:32\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:33\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:36\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:37\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:38\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:38\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:40\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:41\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:42\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:42\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:43\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:45\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:46\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:49\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:50\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:57\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:58\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:06:59\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:03\n",
      "  Batch   520  of    531.    Elapsed: 0:07:03.\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:07\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "  Average training loss: 1.72\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.45\n",
      "  Validation Loss: 1.70\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:05\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:08\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:09\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:10\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:12\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:16\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:17\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:18\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:19\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:21\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:22\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:25\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:26\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:29\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:30\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:31\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "  Batch    40  of    531.    Elapsed: 0:00:33.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:35\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:36\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:43\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:44\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:48\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:49\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:51\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:52\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:56\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:57\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:58\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:00\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:01\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:02\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:04\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:05\n",
      "  Batch    80  of    531.    Elapsed: 0:01:05.\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:13\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:14\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:15\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:18\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:19\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:20\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:20\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:22\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:23\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:28\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:33\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:33\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:35\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:36\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:37\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:38\n",
      "  Batch   120  of    531.    Elapsed: 0:01:38.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:40\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:41\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:44\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:45\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:48\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:49\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:50\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:52\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:53\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:54\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:58\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:01:59\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:59\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:01\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:02\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:08\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:08\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:10\n",
      "  Batch   160  of    531.    Elapsed: 0:02:10.\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:11\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:12\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:12\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:14\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:15\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:16\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:19\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:20\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:21\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:21\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:23\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:24\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:29\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:32\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:33\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:37\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:38\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:40\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:41\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:43\n",
      "  Batch   200  of    531.    Elapsed: 0:02:43.\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:43\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:45\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:46\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:49\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:51\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:55\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:02:58\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:12\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:15\n",
      "  Batch   240  of    531.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:17\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:37\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:39\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:41\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:42\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:43\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:44\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:44\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:46\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:47\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:48\n",
      "  Batch   280  of    531.    Elapsed: 0:03:48.\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:48\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:50\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:51\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:52\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:54\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:55\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:03:56\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:57\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:57\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:03:59\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:00\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:01\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:01\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:03\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:04\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:05\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:08\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:09\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:10\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:10\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:12\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:13\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:14\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:16\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:17\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:18\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:20\n",
      "  Batch   320  of    531.    Elapsed: 0:04:20.\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:21\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:22\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:25\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:26\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:27\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:29\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:30\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:31\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:34\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:35\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:36\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:36\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:38\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:39\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:40\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:42\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:43\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:44\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:45\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:45\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:47\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:48\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:49\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:49\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:51\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:04:53\n",
      "  Batch   360  of    531.    Elapsed: 0:04:53.\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:55\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:58\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:04:58\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:02\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:02\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:04\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:05\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:06\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:08\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:09\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:10\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:11\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:11\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:13\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:15\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:15\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:17\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:18\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:19\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:21\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:22\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:23\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:24\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:24\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:25\n",
      "  Batch   400  of    531.    Elapsed: 0:05:25.\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:26\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:27\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:28\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:28\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:30\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:31\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:32\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:34\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:35\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:36\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:37\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:37\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:39\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:40\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:41\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:44\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:45\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:46\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:49\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:52\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:05:53\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:54\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:56\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:57\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:05:58\n",
      "  Batch   440  of    531.    Elapsed: 0:05:58.\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:05:59\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:01\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:02\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:03\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:05\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:07\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:10\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:11\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:12\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:14\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:15\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:16\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:18\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:19\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:20\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:23\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:24\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:27\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:28\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:29\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:30\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:30\n",
      "  Batch   480  of    531.    Elapsed: 0:06:30.\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:31\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:32\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:33\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:36\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:37\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:38\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:40\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:41\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:42\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:43\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:45\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:46\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:06:49\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:50\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:53\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:06:57\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:58\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:06:59\n",
      "\n",
      "  Average training loss: 1.66\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.67\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:03\n",
      "  Batch   520  of    531.    Elapsed: 0:07:03.\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "  Average training loss: 1.68\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "  Average training loss: 1.69\n",
      "  Training epcoh took: 0:07:07\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.70\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.46\n",
      "  Validation Loss: 1.66\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:01\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:05\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:07\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:08\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:09\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:10\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:11\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:12\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:13\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:14\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:15\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:16\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:17\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:18\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:19\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:20\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:21\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:00:22\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:25\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:26\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:27\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:28\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:29\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:30\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:31\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "  Batch    40  of    531.    Elapsed: 0:00:33.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 0:00:35\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:36\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:37\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:42\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:43\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:44\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:48\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:49\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:00:50\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:51\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:52\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:55\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:00:56\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:57\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:58\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:59\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:01:00\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:01:01\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:02\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:03\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:04\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:05\n",
      "  Batch    80  of    531.    Elapsed: 0:01:05.\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:08\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "  Average training loss: 0.27\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:12\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:13\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:14\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:01:16\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:18\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:01:19\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:20\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:01:21\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:22\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:23\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:25\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:28\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:29\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:33\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:34\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:35\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:36\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:37\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:38\n",
      "  Batch   120  of    531.    Elapsed: 0:01:38.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:40\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:41\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:42\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:43\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:44\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:01:45\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:01:47\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:48\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:49\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:01:50\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:52\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:53\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:54\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:58\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:59\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:02:00\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:01\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:02\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:08\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:10\n",
      "  Batch   160  of    531.    Elapsed: 0:02:10.\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:11\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:02:12\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:13\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:02:14\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:15\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:16\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:02:17\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:02:19\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:20\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:21\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:22\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:23\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:24\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:02:27\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:28\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:29\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:30\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:31\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:02:32\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:33\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:37\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:02:38\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:39\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:02:40\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:41\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:43\n",
      "  Batch   200  of    531.    Elapsed: 0:02:43.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:44\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:02:45\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:46\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:47\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:48\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:49\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:51\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:55\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:57\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:02:58\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:03:00\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:05\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:06\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:07\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:08\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:03:11\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:12\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:13\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.74\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:15\n",
      "  Batch   240  of    531.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:03:17\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:18\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 0:03:19\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:20\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:21\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:22\n",
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:23\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:24\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:25\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:26\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:27\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:28\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:29\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.81\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:33\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:34\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:35\n",
      "\n",
      "  Average training loss: 0.82\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:36\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:37\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:03:38\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:39\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:40\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:41\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:42\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:43\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:03:44\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:45\n",
      "\n",
      "  Average training loss: 0.86\n",
      "  Training epcoh took: 0:03:46\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:47\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:48\n",
      "  Batch   280  of    531.    Elapsed: 0:03:48.\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.87\n",
      "  Training epcoh took: 0:03:49\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:50\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:51\n",
      "\n",
      "  Average training loss: 0.88\n",
      "  Training epcoh took: 0:03:52\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:54\n",
      "\n",
      "  Average training loss: 0.89\n",
      "  Training epcoh took: 0:03:54\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:55\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:56\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:03:57\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:58\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:03:59\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:04:00\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:04:01\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:04:02\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:04:03\n",
      "\n",
      "  Average training loss: 0.93\n",
      "  Training epcoh took: 0:04:04\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:04:05\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:04:06\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 0.94\n",
      "  Training epcoh took: 0:04:07\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:08\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:09\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:04:10\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:11\n",
      "\n",
      "  Average training loss: 0.96\n",
      "  Training epcoh took: 0:04:12\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:13\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:14\n",
      "\n",
      "  Average training loss: 0.97\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:15\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:16\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:17\n",
      "\n",
      "  Average training loss: 0.98\n",
      "  Training epcoh took: 0:04:18\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:20\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:04:20\n",
      "  Batch   320  of    531.    Elapsed: 0:04:20.\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:21\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:22\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:25\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:04:26\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:27\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:28\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:29\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:30\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:04:31\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:04:33\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:34\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:35\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:04:36\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:37\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:04:38\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:39\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:40\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:04:41\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:42\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:42\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:04:43\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:44\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:45\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:46\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epcoh took: 0:04:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:47\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:48\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epcoh took: 0:04:49\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:50\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:04:51\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:52\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:53\n",
      "  Batch   360  of    531.    Elapsed: 0:04:53.\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:04:54\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:55\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:55\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:56\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:04:57\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:58\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:04:59\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:05:02\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:05:03\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:05:04\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:05:05\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:05:06\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epcoh took: 0:05:07\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:05:08\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:05:08\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:05:09\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:10\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:11\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:05:12\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:13\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:14\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epcoh took: 0:05:15\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epcoh took: 0:05:16\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:17\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:18\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:19\n",
      "\n",
      "  Average training loss: 1.22\n",
      "  Training epcoh took: 0:05:20\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:21\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:21\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:05:22\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:23\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:24\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:05:25\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:25\n",
      "  Batch   400  of    531.    Elapsed: 0:05:25.\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:26\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:05:27\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:28\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:05:29\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:30\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:31\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epcoh took: 0:05:32\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:33\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:34\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:34\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epcoh took: 0:05:35\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:36\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:37\n",
      "\n",
      "  Average training loss: 1.29\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:38\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:39\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epcoh took: 0:05:40\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:41\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "  Average training loss: 1.31\n",
      "  Training epcoh took: 0:05:43\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:44\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:45\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:05:46\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:47\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:49\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.34\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:52\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:53\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epcoh took: 0:05:54\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:55\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:56\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:56\n",
      "\n",
      "  Average training loss: 1.36\n",
      "  Training epcoh took: 0:05:57\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:58\n",
      "  Batch   440  of    531.    Elapsed: 0:05:58.\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:05:59\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:06:00\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:06:01\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epcoh took: 0:06:02\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:06:03\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epcoh took: 0:06:05\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:06:05\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "  Average training loss: 1.40\n",
      "  Training epcoh took: 0:06:07\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:06:10\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:06:11\n",
      "\n",
      "  Average training loss: 1.42\n",
      "  Training epcoh took: 0:06:12\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "  Average training loss: 1.43\n",
      "  Training epcoh took: 0:06:14\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:15\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:16\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:06:17\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:18\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:18\n",
      "\n",
      "  Average training loss: 1.45\n",
      "  Training epcoh took: 0:06:19\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:20\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:21\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:23\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:24\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "  Average training loss: 1.48\n",
      "  Training epcoh took: 0:06:27\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:28\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:29\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:30\n",
      "\n",
      "  Average training loss: 1.49\n",
      "  Training epcoh took: 0:06:31\n",
      "  Batch   480  of    531.    Elapsed: 0:06:31.\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:31\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epcoh took: 0:06:33\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:34\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.51\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:36\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:37\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:38\n",
      "\n",
      "  Average training loss: 1.52\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:40\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epcoh took: 0:06:41\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:42\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:43\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:45\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:06:46\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:06:49\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:50\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:53\n",
      "\n",
      "  Average training loss: 1.58\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "  Average training loss: 1.59\n",
      "  Training epcoh took: 0:06:57\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:57\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:58\n",
      "\n",
      "  Average training loss: 1.60\n",
      "  Training epcoh took: 0:06:59\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:07:00\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:07:03\n",
      "  Batch   520  of    531.    Elapsed: 0:07:03.\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "  Average training loss: 1.62\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "  Average training loss: 1.63\n",
      "  Training epcoh took: 0:07:07\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "  Average training loss: 1.64\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.46\n",
      "  Validation Loss: 1.64\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:29:40 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "#дообучение и валидация модели\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Обучение\n",
    "    # Переводим модель в training mode\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            \n",
    "        # добавляем батч для вычисления на GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Распаковываем данные из dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        (loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        train_loss_set.append(loss.item())  \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        #средний loss по всем батчам\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # Рисуем график\n",
    "        #clear_output(True)\n",
    "        #plt.plot(train_loss_set)\n",
    "        #plt.title(\"Training loss\")\n",
    "        #plt.xlabel(\"Batch\")\n",
    "        #plt.ylabel(\"Loss\")\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Переводим модель в evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    valid_preds, valid_labels = [], []\n",
    "\n",
    "    for batch in validation_dataloader:   \n",
    "        # добавляем батч для вычисления на GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Распаковываем данные из dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "        # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "        with torch.no_grad():\n",
    "            (loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.75</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.72</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0:07:11</td>\n",
       "      <td>0:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.65</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               1.75         1.71           0.45       0:07:12         0:00:14\n",
       "2               1.72         1.70           0.45       0:07:11         0:00:13\n",
       "3               1.71         1.66           0.46       0:07:12         0:00:13\n",
       "4               1.65         1.64           0.46       0:07:12         0:00:13"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Рассмотрим сводку тренировочного процесса.\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /notebooks/BERT_MODEL_PRETRAINED-bert_large_uncased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/notebooks/BERT_MODEL_PRETRAINED-bert_large_uncased/vocab.txt',\n",
       " '/notebooks/BERT_MODEL_PRETRAINED-bert_large_uncased/special_tokens_map.json',\n",
       " '/notebooks/BERT_MODEL_PRETRAINED-bert_large_uncased/added_tokens.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сохранение модели\n",
    "\n",
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = '/notebooks/BERT_MODEL_PRETRAINED-bert_large_uncased'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузка модели\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# Оценка качества на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAN0LZBOOPVh"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=50,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(test_gt)\n",
    "\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs,\n",
    "    prediction_masks,\n",
    "    prediction_labels\n",
    ")\n",
    "\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, \n",
    "    sampler=SequentialSampler(prediction_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hba10sXR7Xi6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 4717 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print(f'Predicting labels for {len(input_ids)} test sentences...')\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Сохраняем предсказанные классы и исходные метки\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "#print(predictions)\n",
    "#print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 2278 of 4717 (48.293406826372696 %)\n"
     ]
    }
   ],
   "source": [
    "#вывести процент верно угаданных меток\n",
    "true_counter = 0\n",
    "all_counter = 0\n",
    "for i in range(len(true_labels)):\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "    for pred_label, true_label in zip(pred_labels_i, true_labels[i]):\n",
    "        if pred_label==true_label:\n",
    "            true_counter = true_counter + 1\n",
    "        all_counter = all_counter + 1\n",
    "print(f'Positive samples: {true_counter} of {all_counter} ({(true_counter/all_counter)*100} %)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет метрик качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000        60\n",
      "           1    0.00000   0.00000   0.00000       135\n",
      "           2    0.47757   0.98341   0.64292      2230\n",
      "           3    0.00000   0.00000   0.00000         5\n",
      "           4    0.00000   0.00000   0.00000        31\n",
      "           5    0.00000   0.00000   0.00000        28\n",
      "           6    0.00000   0.00000   0.00000        17\n",
      "           7    0.00000   0.00000   0.00000         8\n",
      "           8    0.00000   0.00000   0.00000        33\n",
      "           9    0.00000   0.00000   0.00000        38\n",
      "          10    0.68000   0.42929   0.52632       198\n",
      "          12    0.00000   0.00000   0.00000       183\n",
      "          13    0.00000   0.00000   0.00000         1\n",
      "          14    0.00000   0.00000   0.00000       338\n",
      "          15    0.00000   0.00000   0.00000        72\n",
      "          16    0.00000   0.00000   0.00000        95\n",
      "          17    0.00000   0.00000   0.00000         7\n",
      "          18    0.00000   0.00000   0.00000         6\n",
      "          19    0.00000   0.00000   0.00000         1\n",
      "          20    0.00000   0.00000   0.00000         2\n",
      "          21    0.00000   0.00000   0.00000        20\n",
      "          22    0.00000   0.00000   0.00000         4\n",
      "          23    0.00000   0.00000   0.00000      1194\n",
      "          24    0.00000   0.00000   0.00000         8\n",
      "          25    0.00000   0.00000   0.00000         3\n",
      "\n",
      "    accuracy                        0.48293      4717\n",
      "   macro avg    0.04630   0.05651   0.04677      4717\n",
      "weighted avg    0.25432   0.48293   0.32604      4717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Объединяем результаты батчей\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(classification_report(flat_true_labels, flat_predictions, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "f = sns.heatmap(cm, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы объединим результаты для всех батчей и вычислим окончательную оценку MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.11344\n"
     ]
    }
   ],
   "source": [
    "#Объединяем результаты батчей\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.5f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
